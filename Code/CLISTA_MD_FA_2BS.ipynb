{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"IfDmYam1QCKN","executionInfo":{"status":"ok","timestamp":1680193231551,"user_tz":300,"elapsed":3755,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import keras as keras\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KKhMvODWQCmc","executionInfo":{"status":"ok","timestamp":1680193231551,"user_tz":300,"elapsed":5,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"}}},"outputs":[],"source":["# define problem parameters\n","n = 270\n","N = 1024\n","k = 40\n","\n","num_layers = 15\n","\n","# define number of training/validation/testing samples\n","num_train_samples = 75000\n","num_valid_samples = 25000\n","num_test_samples = 25000\n","total_num_samples = num_train_samples + num_valid_samples + num_test_samples\n","\n","# use default rng\n","rng = np.random.default_rng()\n","\n","# system parameters\n","dual_bs = True\n","fading = True\n","noise = True\n","cmplx = True ## changing this to False won't do anything\n","snr_dB = [-12, -10, -5, 1, 5, 10, 20]\n","num_layers = 15"]},{"cell_type":"markdown","metadata":{"id":"cbJnb9b2mTSo"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UHppsmAqQEkh"},"outputs":[],"source":["# defining functions\n","def tf_cmplx_eta(u,T):\n","  return tf.math.exp(tf.complex(0.0,tf.math.angle(u))) * tf.complex(tf.math.maximum(tf.math.abs(u)-T, 0),0.0)\n","\n","class CRF_LISTALayer(keras.layers.Layer):\n","  \n","  # defining variables for the layer\n","  def __init__(self, A, L, init_alpha, Q, W):\n","    super().__init__()\n","    self.A = A\n","    self.L = L\n","    self.n, self.N = self.A.shape\n","    self.alpha = tf.Variable(initial_value=init_alpha, dtype='float32', trainable=True)\n","    self.Q = tf.Variable(initial_value=init_Q, dtype='complex64', trainable=True)\n","    self.W = tf.Variable(initial_value=init_W, dtype='complex64', trainable=True)\n","\n","  # creating inputs and updating things on each call\n","  def call(self, inputs):\n","    xHt = inputs[:, 0:self.N]\n","    y = inputs[:, self.N:]\n","    update = xHt @ self.Q + y @ self.W\n","    new_x = tf_cmplx_eta(update, self.alpha/self.L)  # this is what makes it differ from other LISTA layer\n","    return tf.concat([new_x, y], axis=1)\n","\n","class CustomMSELoss(keras.losses.Loss):\n","\n","  def __init__(self, N):\n","    super().__init__()\n","    self.N = N\n","  \n","  def call(self, true, pred):\n","    x_true = true[:, 0:self.N]\n","    x_pred = pred[:, 0:self.N]\n","    return tf.reduce_mean(tf.math.squared_difference(tf.complex(x_true,0.0), x_pred))\n","    #return tf.reduce_mean(tf.square(tf.abs(tf.complex(x_true,0.0) - x_pred)))\n","  \n","class CustomMSEMetric(keras.metrics.Mean):\n","\n","  def __init__(self, N):\n","    super().__init__()\n","    self.N = N\n","\n","  def update_state(self, true, pred, sample_weight=None):\n","    x_true = true[:, 0:self.N]\n","    x_pred = pred[:, 0:self.N]\n","    val = tf.reduce_mean(tf.math.squared_difference(tf.complex(x_true,0.0), x_pred))\n","    #val = tf.reduce_mean(tf.square(tf.abs(tf.complex(x_true,0.0) - x_pred)))\n","    return super().update_state(val, sample_weight=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUw_eJW7P77E","executionInfo":{"status":"ok","timestamp":1680186573760,"user_tz":300,"elapsed":3628298,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"}},"outputId":"b855185c-e471-41d2-e0ed-42d102239db4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","586/586 [==============================] - 20s 19ms/step - loss: 0.7212 - mean: 0.7211 - val_loss: 0.0516 - val_mean: 0.0516\n","Epoch 2/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0346 - mean: 0.0346 - val_loss: 0.0256 - val_mean: 0.0256\n","Epoch 3/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0211 - mean: 0.0211 - val_loss: 0.0187 - val_mean: 0.0187\n","Epoch 4/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0165 - mean: 0.0165 - val_loss: 0.0158 - val_mean: 0.0158\n","Epoch 5/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0143 - mean: 0.0143 - val_loss: 0.0141 - val_mean: 0.0141\n","Epoch 6/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0129 - mean: 0.0129 - val_loss: 0.0130 - val_mean: 0.0130\n","Epoch 7/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0120 - mean: 0.0120 - val_loss: 0.0123 - val_mean: 0.0123\n","Epoch 8/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0113 - mean: 0.0113 - val_loss: 0.0119 - val_mean: 0.0119\n","Epoch 9/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0108 - mean: 0.0108 - val_loss: 0.0114 - val_mean: 0.0114\n","Epoch 10/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0103 - mean: 0.0103 - val_loss: 0.0111 - val_mean: 0.0111\n","Epoch 11/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0099 - mean: 0.0099 - val_loss: 0.0108 - val_mean: 0.0108\n","Epoch 12/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0095 - mean: 0.0095 - val_loss: 0.0105 - val_mean: 0.0105\n","Epoch 13/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0092 - mean: 0.0092 - val_loss: 0.0103 - val_mean: 0.0103\n","Epoch 14/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0088 - mean: 0.0088 - val_loss: 0.0101 - val_mean: 0.0101\n","Epoch 15/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0085 - mean: 0.0085 - val_loss: 0.0100 - val_mean: 0.0100\n","Epoch 16/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0081 - mean: 0.0081 - val_loss: 0.0098 - val_mean: 0.0098\n","Epoch 17/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0078 - mean: 0.0078 - val_loss: 0.0096 - val_mean: 0.0096\n","Epoch 18/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0075 - mean: 0.0075 - val_loss: 0.0094 - val_mean: 0.0094\n","Epoch 19/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0071 - mean: 0.0071 - val_loss: 0.0092 - val_mean: 0.0092\n","Epoch 20/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0068 - mean: 0.0068 - val_loss: 0.0090 - val_mean: 0.0090\n","Epoch 21/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0064 - mean: 0.0064 - val_loss: 0.0088 - val_mean: 0.0088\n","Epoch 22/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0061 - mean: 0.0061 - val_loss: 0.0086 - val_mean: 0.0086\n","Epoch 23/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0057 - mean: 0.0057 - val_loss: 0.0084 - val_mean: 0.0084\n","Epoch 24/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0054 - mean: 0.0054 - val_loss: 0.0083 - val_mean: 0.0083\n","Epoch 25/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0050 - mean: 0.0050 - val_loss: 0.0081 - val_mean: 0.0081\n","Epoch 26/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0047 - mean: 0.0047 - val_loss: 0.0080 - val_mean: 0.0080\n","Epoch 27/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0044 - mean: 0.0044 - val_loss: 0.0079 - val_mean: 0.0079\n","Epoch 28/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0041 - mean: 0.0041 - val_loss: 0.0078 - val_mean: 0.0078\n","Epoch 29/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0039 - mean: 0.0039 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 30/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0036 - mean: 0.0036 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 31/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0033 - mean: 0.0033 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 32/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0031 - mean: 0.0031 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 33/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0029 - mean: 0.0029 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 34/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0027 - mean: 0.0027 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 35/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0025 - mean: 0.0025 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 36/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0024 - mean: 0.0024 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 37/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0023 - mean: 0.0023 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 38/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0021 - mean: 0.0021 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 39/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0020 - mean: 0.0020 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 40/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0019 - mean: 0.0019 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 41/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0019 - mean: 0.0019 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 42/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0018 - mean: 0.0018 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 43/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0017 - mean: 0.0017 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 44/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0016 - mean: 0.0016 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 45/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0016 - mean: 0.0016 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 46/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0015 - mean: 0.0015 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 47/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0015 - mean: 0.0015 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 48/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0014 - mean: 0.0014 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 49/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0014 - mean: 0.0014 - val_loss: 0.0077 - val_mean: 0.0077\n","Epoch 50/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0077 - val_mean: 0.0077\n","782/782 [==============================] - 3s 4ms/step - loss: 0.0077 - mean: 0.0077\n","Final MSE on test data: 0.007729612290859222\n","writing to files\n","782/782 [==============================] - 3s 3ms/step\n","file writing done\n","Epoch 1/50\n","586/586 [==============================] - 15s 19ms/step - loss: 0.4878 - mean: 0.4877 - val_loss: 0.0386 - val_mean: 0.0386\n","Epoch 2/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0264 - mean: 0.0264 - val_loss: 0.0197 - val_mean: 0.0197\n","Epoch 3/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0163 - mean: 0.0163 - val_loss: 0.0147 - val_mean: 0.0147\n","Epoch 4/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0130 - mean: 0.0130 - val_loss: 0.0124 - val_mean: 0.0124\n","Epoch 5/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0112 - mean: 0.0112 - val_loss: 0.0111 - val_mean: 0.0111\n","Epoch 6/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0101 - mean: 0.0101 - val_loss: 0.0103 - val_mean: 0.0103\n","Epoch 7/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0094 - mean: 0.0094 - val_loss: 0.0097 - val_mean: 0.0097\n","Epoch 8/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0088 - mean: 0.0088 - val_loss: 0.0092 - val_mean: 0.0092\n","Epoch 9/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0082 - mean: 0.0082 - val_loss: 0.0088 - val_mean: 0.0088\n","Epoch 10/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0078 - mean: 0.0078 - val_loss: 0.0085 - val_mean: 0.0085\n","Epoch 11/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0074 - mean: 0.0074 - val_loss: 0.0082 - val_mean: 0.0082\n","Epoch 12/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0070 - mean: 0.0070 - val_loss: 0.0080 - val_mean: 0.0080\n","Epoch 13/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0066 - mean: 0.0066 - val_loss: 0.0078 - val_mean: 0.0078\n","Epoch 14/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0063 - mean: 0.0063 - val_loss: 0.0076 - val_mean: 0.0076\n","Epoch 15/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0060 - mean: 0.0060 - val_loss: 0.0074 - val_mean: 0.0074\n","Epoch 16/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0057 - mean: 0.0057 - val_loss: 0.0073 - val_mean: 0.0073\n","Epoch 17/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0054 - mean: 0.0054 - val_loss: 0.0071 - val_mean: 0.0071\n","Epoch 18/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0052 - mean: 0.0052 - val_loss: 0.0070 - val_mean: 0.0070\n","Epoch 19/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0049 - mean: 0.0049 - val_loss: 0.0068 - val_mean: 0.0068\n","Epoch 20/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0047 - mean: 0.0047 - val_loss: 0.0066 - val_mean: 0.0066\n","Epoch 21/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0044 - mean: 0.0044 - val_loss: 0.0065 - val_mean: 0.0065\n","Epoch 22/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0041 - mean: 0.0041 - val_loss: 0.0063 - val_mean: 0.0063\n","Epoch 23/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0038 - mean: 0.0038 - val_loss: 0.0062 - val_mean: 0.0062\n","Epoch 24/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0036 - mean: 0.0036 - val_loss: 0.0060 - val_mean: 0.0060\n","Epoch 25/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0034 - mean: 0.0034 - val_loss: 0.0059 - val_mean: 0.0059\n","Epoch 26/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0031 - mean: 0.0031 - val_loss: 0.0058 - val_mean: 0.0058\n","Epoch 27/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0029 - mean: 0.0029 - val_loss: 0.0057 - val_mean: 0.0057\n","Epoch 28/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0027 - mean: 0.0027 - val_loss: 0.0057 - val_mean: 0.0057\n","Epoch 29/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0025 - mean: 0.0025 - val_loss: 0.0056 - val_mean: 0.0056\n","Epoch 30/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0023 - mean: 0.0023 - val_loss: 0.0056 - val_mean: 0.0056\n","Epoch 31/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0022 - mean: 0.0022 - val_loss: 0.0055 - val_mean: 0.0056\n","Epoch 32/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0020 - mean: 0.0020 - val_loss: 0.0055 - val_mean: 0.0055\n","Epoch 33/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0019 - mean: 0.0019 - val_loss: 0.0055 - val_mean: 0.0055\n","Epoch 34/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0018 - mean: 0.0018 - val_loss: 0.0055 - val_mean: 0.0055\n","Epoch 35/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0017 - mean: 0.0017 - val_loss: 0.0055 - val_mean: 0.0055\n","Epoch 36/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0016 - mean: 0.0016 - val_loss: 0.0055 - val_mean: 0.0055\n","Epoch 37/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0015 - mean: 0.0015 - val_loss: 0.0054 - val_mean: 0.0055\n","Epoch 38/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0014 - mean: 0.0014 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 39/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 40/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 41/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0012 - mean: 0.0012 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 42/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0012 - mean: 0.0012 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 43/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 44/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 45/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0010 - mean: 0.0010 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 46/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.8801e-04 - mean: 9.8802e-04 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 47/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.5539e-04 - mean: 9.5539e-04 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 48/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.1896e-04 - mean: 9.1896e-04 - val_loss: 0.0053 - val_mean: 0.0053\n","Epoch 49/50\n","586/586 [==============================] - 10s 16ms/step - loss: 8.8778e-04 - mean: 8.8778e-04 - val_loss: 0.0053 - val_mean: 0.0053\n","Epoch 50/50\n","586/586 [==============================] - 10s 16ms/step - loss: 8.5877e-04 - mean: 8.5877e-04 - val_loss: 0.0053 - val_mean: 0.0053\n","782/782 [==============================] - 3s 4ms/step - loss: 0.0053 - mean: 0.0053\n","Final MSE on test data: 0.005323875229805708\n","writing to files\n","782/782 [==============================] - 3s 3ms/step\n","file writing done\n","Epoch 1/50\n","586/586 [==============================] - 14s 18ms/step - loss: 0.3792 - mean: 0.3792 - val_loss: 0.0309 - val_mean: 0.0309\n","Epoch 2/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0202 - mean: 0.0202 - val_loss: 0.0144 - val_mean: 0.0144\n","Epoch 3/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0115 - mean: 0.0115 - val_loss: 0.0100 - val_mean: 0.0100\n","Epoch 4/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0085 - mean: 0.0085 - val_loss: 0.0080 - val_mean: 0.0080\n","Epoch 5/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0069 - mean: 0.0069 - val_loss: 0.0068 - val_mean: 0.0068\n","Epoch 6/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0059 - mean: 0.0059 - val_loss: 0.0060 - val_mean: 0.0060\n","Epoch 7/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0052 - mean: 0.0052 - val_loss: 0.0054 - val_mean: 0.0054\n","Epoch 8/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0047 - mean: 0.0047 - val_loss: 0.0050 - val_mean: 0.0050\n","Epoch 9/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0042 - mean: 0.0042 - val_loss: 0.0046 - val_mean: 0.0046\n","Epoch 10/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0038 - mean: 0.0038 - val_loss: 0.0043 - val_mean: 0.0043\n","Epoch 11/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0034 - mean: 0.0034 - val_loss: 0.0040 - val_mean: 0.0040\n","Epoch 12/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0031 - mean: 0.0031 - val_loss: 0.0038 - val_mean: 0.0038\n","Epoch 13/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0029 - mean: 0.0029 - val_loss: 0.0037 - val_mean: 0.0037\n","Epoch 14/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0027 - mean: 0.0027 - val_loss: 0.0035 - val_mean: 0.0035\n","Epoch 15/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0025 - mean: 0.0025 - val_loss: 0.0035 - val_mean: 0.0035\n","Epoch 16/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0024 - mean: 0.0024 - val_loss: 0.0034 - val_mean: 0.0034\n","Epoch 17/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0023 - mean: 0.0023 - val_loss: 0.0033 - val_mean: 0.0033\n","Epoch 18/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0022 - mean: 0.0022 - val_loss: 0.0032 - val_mean: 0.0032\n","Epoch 19/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0021 - mean: 0.0021 - val_loss: 0.0031 - val_mean: 0.0031\n","Epoch 20/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0020 - mean: 0.0020 - val_loss: 0.0030 - val_mean: 0.0030\n","Epoch 21/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0018 - mean: 0.0018 - val_loss: 0.0029 - val_mean: 0.0029\n","Epoch 22/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0017 - mean: 0.0017 - val_loss: 0.0028 - val_mean: 0.0028\n","Epoch 23/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0016 - mean: 0.0016 - val_loss: 0.0026 - val_mean: 0.0026\n","Epoch 24/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0014 - mean: 0.0014 - val_loss: 0.0025 - val_mean: 0.0025\n","Epoch 25/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0024 - val_mean: 0.0024\n","Epoch 26/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0012 - mean: 0.0012 - val_loss: 0.0023 - val_mean: 0.0023\n","Epoch 27/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0023 - val_mean: 0.0023\n","Epoch 28/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0010 - mean: 0.0010 - val_loss: 0.0022 - val_mean: 0.0022\n","Epoch 29/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.2200e-04 - mean: 9.2201e-04 - val_loss: 0.0021 - val_mean: 0.0021\n","Epoch 30/50\n","586/586 [==============================] - 10s 16ms/step - loss: 8.4994e-04 - mean: 8.4995e-04 - val_loss: 0.0021 - val_mean: 0.0021\n","Epoch 31/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.9113e-04 - mean: 7.9114e-04 - val_loss: 0.0020 - val_mean: 0.0020\n","Epoch 32/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.3095e-04 - mean: 7.3095e-04 - val_loss: 0.0020 - val_mean: 0.0020\n","Epoch 33/50\n","586/586 [==============================] - 10s 16ms/step - loss: 6.8257e-04 - mean: 6.8258e-04 - val_loss: 0.0019 - val_mean: 0.0019\n","Epoch 34/50\n","586/586 [==============================] - 10s 16ms/step - loss: 6.3743e-04 - mean: 6.3744e-04 - val_loss: 0.0019 - val_mean: 0.0019\n","Epoch 35/50\n","586/586 [==============================] - 10s 17ms/step - loss: 5.9657e-04 - mean: 5.9658e-04 - val_loss: 0.0019 - val_mean: 0.0019\n","Epoch 36/50\n","586/586 [==============================] - 10s 17ms/step - loss: 5.6214e-04 - mean: 5.6214e-04 - val_loss: 0.0019 - val_mean: 0.0019\n","Epoch 37/50\n","586/586 [==============================] - 10s 16ms/step - loss: 5.2864e-04 - mean: 5.2865e-04 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 38/50\n","586/586 [==============================] - 10s 17ms/step - loss: 5.0104e-04 - mean: 5.0104e-04 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 39/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.7435e-04 - mean: 4.7435e-04 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 40/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.5023e-04 - mean: 4.5023e-04 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 41/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.2744e-04 - mean: 4.2744e-04 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 42/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.0635e-04 - mean: 4.0635e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 43/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.8997e-04 - mean: 3.8997e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 44/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.7437e-04 - mean: 3.7437e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 45/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.5857e-04 - mean: 3.5857e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 46/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.4357e-04 - mean: 3.4358e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 47/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.3038e-04 - mean: 3.3038e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 48/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.1685e-04 - mean: 3.1685e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 49/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.0561e-04 - mean: 3.0561e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 50/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.9581e-04 - mean: 2.9581e-04 - val_loss: 0.0017 - val_mean: 0.0017\n","782/782 [==============================] - 3s 4ms/step - loss: 0.0017 - mean: 0.0017\n","Final MSE on test data: 0.0016535664908587933\n","writing to files\n","782/782 [==============================] - 3s 3ms/step\n","file writing done\n","Epoch 1/50\n","586/586 [==============================] - 15s 18ms/step - loss: 0.3577 - mean: 0.3577 - val_loss: 0.0279 - val_mean: 0.0279\n","Epoch 2/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0179 - mean: 0.0179 - val_loss: 0.0125 - val_mean: 0.0125\n","Epoch 3/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0098 - mean: 0.0098 - val_loss: 0.0084 - val_mean: 0.0084\n","Epoch 4/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0071 - mean: 0.0071 - val_loss: 0.0066 - val_mean: 0.0066\n","Epoch 5/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0056 - mean: 0.0056 - val_loss: 0.0055 - val_mean: 0.0055\n","Epoch 6/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0047 - mean: 0.0047 - val_loss: 0.0047 - val_mean: 0.0047\n","Epoch 7/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0040 - mean: 0.0040 - val_loss: 0.0041 - val_mean: 0.0041\n","Epoch 8/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0034 - mean: 0.0034 - val_loss: 0.0036 - val_mean: 0.0036\n","Epoch 9/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0030 - mean: 0.0030 - val_loss: 0.0033 - val_mean: 0.0033\n","Epoch 10/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0026 - mean: 0.0026 - val_loss: 0.0030 - val_mean: 0.0030\n","Epoch 11/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0023 - mean: 0.0023 - val_loss: 0.0027 - val_mean: 0.0027\n","Epoch 12/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0020 - mean: 0.0020 - val_loss: 0.0025 - val_mean: 0.0025\n","Epoch 13/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0018 - mean: 0.0018 - val_loss: 0.0024 - val_mean: 0.0024\n","Epoch 14/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0017 - mean: 0.0017 - val_loss: 0.0023 - val_mean: 0.0023\n","Epoch 15/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0016 - mean: 0.0016 - val_loss: 0.0022 - val_mean: 0.0022\n","Epoch 16/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0015 - mean: 0.0015 - val_loss: 0.0021 - val_mean: 0.0021\n","Epoch 17/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0014 - mean: 0.0014 - val_loss: 0.0021 - val_mean: 0.0021\n","Epoch 18/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0020 - val_mean: 0.0020\n","Epoch 19/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0019 - val_mean: 0.0019\n","Epoch 20/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0012 - mean: 0.0012 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 21/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 22/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0010 - mean: 0.0010 - val_loss: 0.0016 - val_mean: 0.0016\n","Epoch 23/50\n","586/586 [==============================] - 10s 17ms/step - loss: 9.5085e-04 - mean: 9.5085e-04 - val_loss: 0.0015 - val_mean: 0.0015\n","Epoch 24/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.6195e-04 - mean: 8.6196e-04 - val_loss: 0.0014 - val_mean: 0.0014\n","Epoch 25/50\n","586/586 [==============================] - 10s 17ms/step - loss: 7.8145e-04 - mean: 7.8146e-04 - val_loss: 0.0013 - val_mean: 0.0013\n","Epoch 26/50\n","586/586 [==============================] - 10s 17ms/step - loss: 7.0702e-04 - mean: 7.0703e-04 - val_loss: 0.0013 - val_mean: 0.0013\n","Epoch 27/50\n","586/586 [==============================] - 10s 17ms/step - loss: 6.4125e-04 - mean: 6.4126e-04 - val_loss: 0.0012 - val_mean: 0.0012\n","Epoch 28/50\n","586/586 [==============================] - 10s 17ms/step - loss: 5.8199e-04 - mean: 5.8199e-04 - val_loss: 0.0011 - val_mean: 0.0011\n","Epoch 29/50\n","586/586 [==============================] - 10s 17ms/step - loss: 5.2844e-04 - mean: 5.2844e-04 - val_loss: 0.0011 - val_mean: 0.0011\n","Epoch 30/50\n","586/586 [==============================] - 10s 17ms/step - loss: 4.7974e-04 - mean: 4.7974e-04 - val_loss: 0.0010 - val_mean: 0.0010\n","Epoch 31/50\n","586/586 [==============================] - 10s 17ms/step - loss: 4.4305e-04 - mean: 4.4305e-04 - val_loss: 9.7235e-04 - val_mean: 9.7227e-04\n","Epoch 32/50\n","586/586 [==============================] - 10s 17ms/step - loss: 4.0931e-04 - mean: 4.0931e-04 - val_loss: 9.3615e-04 - val_mean: 9.3603e-04\n","Epoch 33/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.7781e-04 - mean: 3.7781e-04 - val_loss: 9.0726e-04 - val_mean: 9.0723e-04\n","Epoch 34/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.5228e-04 - mean: 3.5229e-04 - val_loss: 8.7928e-04 - val_mean: 8.7920e-04\n","Epoch 35/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.2685e-04 - mean: 3.2686e-04 - val_loss: 8.5538e-04 - val_mean: 8.5534e-04\n","Epoch 36/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.0691e-04 - mean: 3.0691e-04 - val_loss: 8.3469e-04 - val_mean: 8.3461e-04\n","Epoch 37/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.8708e-04 - mean: 2.8709e-04 - val_loss: 8.1238e-04 - val_mean: 8.1229e-04\n","Epoch 38/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.6927e-04 - mean: 2.6927e-04 - val_loss: 7.9657e-04 - val_mean: 7.9654e-04\n","Epoch 39/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.5412e-04 - mean: 2.5412e-04 - val_loss: 7.7804e-04 - val_mean: 7.7800e-04\n","Epoch 40/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.4081e-04 - mean: 2.4081e-04 - val_loss: 7.6933e-04 - val_mean: 7.6930e-04\n","Epoch 41/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.2802e-04 - mean: 2.2802e-04 - val_loss: 7.5540e-04 - val_mean: 7.5536e-04\n","Epoch 42/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.1583e-04 - mean: 2.1583e-04 - val_loss: 7.3934e-04 - val_mean: 7.3927e-04\n","Epoch 43/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.0577e-04 - mean: 2.0577e-04 - val_loss: 7.3332e-04 - val_mean: 7.3329e-04\n","Epoch 44/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.9726e-04 - mean: 1.9726e-04 - val_loss: 7.2412e-04 - val_mean: 7.2411e-04\n","Epoch 45/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.8774e-04 - mean: 1.8774e-04 - val_loss: 7.1200e-04 - val_mean: 7.1192e-04\n","Epoch 46/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.7944e-04 - mean: 1.7944e-04 - val_loss: 7.0457e-04 - val_mean: 7.0454e-04\n","Epoch 47/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.7247e-04 - mean: 1.7247e-04 - val_loss: 6.9752e-04 - val_mean: 6.9746e-04\n","Epoch 48/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.6509e-04 - mean: 1.6509e-04 - val_loss: 6.8557e-04 - val_mean: 6.8541e-04\n","Epoch 49/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.5854e-04 - mean: 1.5854e-04 - val_loss: 6.8285e-04 - val_mean: 6.8274e-04\n","Epoch 50/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.5213e-04 - mean: 1.5213e-04 - val_loss: 6.7389e-04 - val_mean: 6.7373e-04\n","782/782 [==============================] - 3s 4ms/step - loss: 6.7204e-04 - mean: 6.7196e-04\n","Final MSE on test data: 0.0006720414967276156\n","writing to files\n","782/782 [==============================] - 4s 3ms/step\n","file writing done\n","Epoch 1/50\n","586/586 [==============================] - 15s 18ms/step - loss: 0.3258 - mean: 0.3258 - val_loss: 0.0256 - val_mean: 0.0256\n","Epoch 2/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0163 - mean: 0.0163 - val_loss: 0.0113 - val_mean: 0.0113\n","Epoch 3/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0088 - mean: 0.0088 - val_loss: 0.0075 - val_mean: 0.0075\n","Epoch 4/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0062 - mean: 0.0062 - val_loss: 0.0058 - val_mean: 0.0058\n","Epoch 5/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0049 - mean: 0.0049 - val_loss: 0.0048 - val_mean: 0.0048\n","Epoch 6/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0040 - mean: 0.0040 - val_loss: 0.0040 - val_mean: 0.0040\n","Epoch 7/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0033 - mean: 0.0033 - val_loss: 0.0035 - val_mean: 0.0035\n","Epoch 8/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0028 - mean: 0.0028 - val_loss: 0.0030 - val_mean: 0.0030\n","Epoch 9/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0023 - mean: 0.0023 - val_loss: 0.0026 - val_mean: 0.0026\n","Epoch 10/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0020 - mean: 0.0020 - val_loss: 0.0023 - val_mean: 0.0023\n","Epoch 11/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0017 - mean: 0.0017 - val_loss: 0.0021 - val_mean: 0.0021\n","Epoch 12/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0015 - mean: 0.0015 - val_loss: 0.0020 - val_mean: 0.0020\n","Epoch 13/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0014 - mean: 0.0014 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 14/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 15/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0012 - mean: 0.0012 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 16/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0016 - val_mean: 0.0016\n","Epoch 17/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0016 - val_mean: 0.0016\n","Epoch 18/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0010 - mean: 0.0010 - val_loss: 0.0015 - val_mean: 0.0015\n","Epoch 19/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.8157e-04 - mean: 9.8158e-04 - val_loss: 0.0014 - val_mean: 0.0014\n","Epoch 20/50\n","586/586 [==============================] - 10s 17ms/step - loss: 9.2421e-04 - mean: 9.2422e-04 - val_loss: 0.0013 - val_mean: 0.0013\n","Epoch 21/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.5700e-04 - mean: 8.5700e-04 - val_loss: 0.0012 - val_mean: 0.0012\n","Epoch 22/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.7811e-04 - mean: 7.7812e-04 - val_loss: 0.0011 - val_mean: 0.0011\n","Epoch 23/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.0189e-04 - mean: 7.0190e-04 - val_loss: 0.0010 - val_mean: 0.0010\n","Epoch 24/50\n","586/586 [==============================] - 10s 16ms/step - loss: 6.2878e-04 - mean: 6.2878e-04 - val_loss: 9.3729e-04 - val_mean: 9.3707e-04\n","Epoch 25/50\n","586/586 [==============================] - 10s 17ms/step - loss: 5.6412e-04 - mean: 5.6412e-04 - val_loss: 8.5874e-04 - val_mean: 8.5862e-04\n","Epoch 26/50\n","586/586 [==============================] - 10s 16ms/step - loss: 5.0449e-04 - mean: 5.0449e-04 - val_loss: 7.8823e-04 - val_mean: 7.8819e-04\n","Epoch 27/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.5207e-04 - mean: 4.5207e-04 - val_loss: 7.3513e-04 - val_mean: 7.3500e-04\n","Epoch 28/50\n","586/586 [==============================] - 10s 17ms/step - loss: 4.0900e-04 - mean: 4.0900e-04 - val_loss: 6.8133e-04 - val_mean: 6.8126e-04\n","Epoch 29/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.6968e-04 - mean: 3.6968e-04 - val_loss: 6.3513e-04 - val_mean: 6.3508e-04\n","Epoch 30/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.3766e-04 - mean: 3.3766e-04 - val_loss: 5.9399e-04 - val_mean: 5.9390e-04\n","Epoch 31/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.0787e-04 - mean: 3.0787e-04 - val_loss: 5.5613e-04 - val_mean: 5.5601e-04\n","Epoch 32/50\n","586/586 [==============================] - 10s 16ms/step - loss: 2.8238e-04 - mean: 2.8238e-04 - val_loss: 5.3190e-04 - val_mean: 5.3179e-04\n","Epoch 33/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.6028e-04 - mean: 2.6028e-04 - val_loss: 5.0076e-04 - val_mean: 5.0065e-04\n","Epoch 34/50\n","586/586 [==============================] - 10s 16ms/step - loss: 2.3982e-04 - mean: 2.3982e-04 - val_loss: 4.8416e-04 - val_mean: 4.8409e-04\n","Epoch 35/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.2328e-04 - mean: 2.2328e-04 - val_loss: 4.5806e-04 - val_mean: 4.5803e-04\n","Epoch 36/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.0758e-04 - mean: 2.0758e-04 - val_loss: 4.4476e-04 - val_mean: 4.4463e-04\n","Epoch 37/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.9445e-04 - mean: 1.9445e-04 - val_loss: 4.2642e-04 - val_mean: 4.2634e-04\n","Epoch 38/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.8186e-04 - mean: 1.8186e-04 - val_loss: 4.1087e-04 - val_mean: 4.1084e-04\n","Epoch 39/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.7090e-04 - mean: 1.7090e-04 - val_loss: 4.0406e-04 - val_mean: 4.0398e-04\n","Epoch 40/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.6158e-04 - mean: 1.6158e-04 - val_loss: 3.9015e-04 - val_mean: 3.9018e-04\n","Epoch 41/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.5260e-04 - mean: 1.5260e-04 - val_loss: 3.8297e-04 - val_mean: 3.8284e-04\n","Epoch 42/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.4525e-04 - mean: 1.4525e-04 - val_loss: 3.7256e-04 - val_mean: 3.7248e-04\n","Epoch 43/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.3784e-04 - mean: 1.3784e-04 - val_loss: 3.6531e-04 - val_mean: 3.6528e-04\n","Epoch 44/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.3152e-04 - mean: 1.3152e-04 - val_loss: 3.5900e-04 - val_mean: 3.5892e-04\n","Epoch 45/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.2488e-04 - mean: 1.2488e-04 - val_loss: 3.5007e-04 - val_mean: 3.4997e-04\n","Epoch 46/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.1891e-04 - mean: 1.1891e-04 - val_loss: 3.4454e-04 - val_mean: 3.4446e-04\n","Epoch 47/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.1436e-04 - mean: 1.1436e-04 - val_loss: 3.3946e-04 - val_mean: 3.3937e-04\n","Epoch 48/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.0928e-04 - mean: 1.0928e-04 - val_loss: 3.3483e-04 - val_mean: 3.3473e-04\n","Epoch 49/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.0550e-04 - mean: 1.0550e-04 - val_loss: 3.2702e-04 - val_mean: 3.2697e-04\n","Epoch 50/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.0113e-04 - mean: 1.0113e-04 - val_loss: 3.2187e-04 - val_mean: 3.2181e-04\n","782/782 [==============================] - 3s 4ms/step - loss: 3.2189e-04 - mean: 3.2188e-04\n","Final MSE on test data: 0.00032189456396736205\n","writing to files\n","782/782 [==============================] - 3s 3ms/step\n","file writing done\n","Epoch 1/50\n","586/586 [==============================] - 14s 18ms/step - loss: 0.1821 - mean: 0.1821 - val_loss: 0.0188 - val_mean: 0.0188\n","Epoch 2/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0120 - mean: 0.0120 - val_loss: 0.0085 - val_mean: 0.0085\n","Epoch 3/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0066 - mean: 0.0066 - val_loss: 0.0057 - val_mean: 0.0057\n","Epoch 4/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0047 - mean: 0.0047 - val_loss: 0.0043 - val_mean: 0.0043\n","Epoch 5/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0036 - mean: 0.0036 - val_loss: 0.0035 - val_mean: 0.0035\n","Epoch 6/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0028 - mean: 0.0028 - val_loss: 0.0029 - val_mean: 0.0029\n","Epoch 7/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0022 - mean: 0.0022 - val_loss: 0.0024 - val_mean: 0.0024\n","Epoch 8/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0018 - mean: 0.0018 - val_loss: 0.0021 - val_mean: 0.0021\n","Epoch 9/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0015 - mean: 0.0015 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 10/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0017 - val_mean: 0.0017\n","Epoch 11/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0015 - val_mean: 0.0015\n","Epoch 12/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0010 - mean: 0.0010 - val_loss: 0.0014 - val_mean: 0.0014\n","Epoch 13/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.5364e-04 - mean: 9.5365e-04 - val_loss: 0.0014 - val_mean: 0.0014\n","Epoch 14/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.9772e-04 - mean: 8.9773e-04 - val_loss: 0.0013 - val_mean: 0.0013\n","Epoch 15/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.6255e-04 - mean: 8.6256e-04 - val_loss: 0.0013 - val_mean: 0.0013\n","Epoch 16/50\n","586/586 [==============================] - 10s 16ms/step - loss: 8.3048e-04 - mean: 8.3048e-04 - val_loss: 0.0012 - val_mean: 0.0012\n","Epoch 17/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.9691e-04 - mean: 7.9691e-04 - val_loss: 0.0011 - val_mean: 0.0011\n","Epoch 18/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.6136e-04 - mean: 7.6137e-04 - val_loss: 0.0011 - val_mean: 0.0011\n","Epoch 19/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.0873e-04 - mean: 7.0873e-04 - val_loss: 9.8234e-04 - val_mean: 9.8234e-04\n","Epoch 20/50\n","586/586 [==============================] - 10s 16ms/step - loss: 6.4605e-04 - mean: 6.4606e-04 - val_loss: 8.9664e-04 - val_mean: 8.9652e-04\n","Epoch 21/50\n","586/586 [==============================] - 10s 16ms/step - loss: 5.7913e-04 - mean: 5.7913e-04 - val_loss: 8.1699e-04 - val_mean: 8.1704e-04\n","Epoch 22/50\n","586/586 [==============================] - 10s 16ms/step - loss: 5.2058e-04 - mean: 5.2058e-04 - val_loss: 7.3871e-04 - val_mean: 7.3881e-04\n","Epoch 23/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.6601e-04 - mean: 4.6601e-04 - val_loss: 6.6559e-04 - val_mean: 6.6567e-04\n","Epoch 24/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.1373e-04 - mean: 4.1373e-04 - val_loss: 6.0213e-04 - val_mean: 6.0211e-04\n","Epoch 25/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.6820e-04 - mean: 3.6820e-04 - val_loss: 5.5026e-04 - val_mean: 5.5024e-04\n","Epoch 26/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.2971e-04 - mean: 3.2971e-04 - val_loss: 5.0459e-04 - val_mean: 5.0459e-04\n","Epoch 27/50\n","586/586 [==============================] - 10s 16ms/step - loss: 2.9632e-04 - mean: 2.9632e-04 - val_loss: 4.5913e-04 - val_mean: 4.5914e-04\n","Epoch 28/50\n","586/586 [==============================] - 10s 16ms/step - loss: 2.6831e-04 - mean: 2.6831e-04 - val_loss: 4.3092e-04 - val_mean: 4.3091e-04\n","Epoch 29/50\n","586/586 [==============================] - 10s 16ms/step - loss: 2.4154e-04 - mean: 2.4154e-04 - val_loss: 3.9818e-04 - val_mean: 3.9819e-04\n","Epoch 30/50\n","586/586 [==============================] - 10s 16ms/step - loss: 2.2172e-04 - mean: 2.2172e-04 - val_loss: 3.6590e-04 - val_mean: 3.6597e-04\n","Epoch 31/50\n","586/586 [==============================] - 10s 16ms/step - loss: 2.0287e-04 - mean: 2.0287e-04 - val_loss: 3.4410e-04 - val_mean: 3.4415e-04\n","Epoch 32/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.8518e-04 - mean: 1.8518e-04 - val_loss: 3.2490e-04 - val_mean: 3.2488e-04\n","Epoch 33/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.7077e-04 - mean: 1.7077e-04 - val_loss: 3.0766e-04 - val_mean: 3.0762e-04\n","Epoch 34/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.5863e-04 - mean: 1.5863e-04 - val_loss: 2.9148e-04 - val_mean: 2.9148e-04\n","Epoch 35/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.4698e-04 - mean: 1.4698e-04 - val_loss: 2.7957e-04 - val_mean: 2.7956e-04\n","Epoch 36/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.3715e-04 - mean: 1.3715e-04 - val_loss: 2.6655e-04 - val_mean: 2.6658e-04\n","Epoch 37/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.2924e-04 - mean: 1.2924e-04 - val_loss: 2.5682e-04 - val_mean: 2.5685e-04\n","Epoch 38/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.2124e-04 - mean: 1.2124e-04 - val_loss: 2.4680e-04 - val_mean: 2.4677e-04\n","Epoch 39/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.1434e-04 - mean: 1.1434e-04 - val_loss: 2.3786e-04 - val_mean: 2.3786e-04\n","Epoch 40/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.0831e-04 - mean: 1.0831e-04 - val_loss: 2.3185e-04 - val_mean: 2.3184e-04\n","Epoch 41/50\n","586/586 [==============================] - 10s 16ms/step - loss: 1.0211e-04 - mean: 1.0211e-04 - val_loss: 2.2455e-04 - val_mean: 2.2455e-04\n","Epoch 42/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.7405e-05 - mean: 9.7405e-05 - val_loss: 2.1805e-04 - val_mean: 2.1802e-04\n","Epoch 43/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.1900e-05 - mean: 9.1900e-05 - val_loss: 2.1168e-04 - val_mean: 2.1167e-04\n","Epoch 44/50\n","586/586 [==============================] - 10s 16ms/step - loss: 8.7795e-05 - mean: 8.7795e-05 - val_loss: 2.0771e-04 - val_mean: 2.0776e-04\n","Epoch 45/50\n","586/586 [==============================] - 10s 16ms/step - loss: 8.4300e-05 - mean: 8.4300e-05 - val_loss: 2.0095e-04 - val_mean: 2.0098e-04\n","Epoch 46/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.0665e-05 - mean: 8.0664e-05 - val_loss: 1.9488e-04 - val_mean: 1.9489e-04\n","Epoch 47/50\n","586/586 [==============================] - 10s 17ms/step - loss: 7.7078e-05 - mean: 7.7078e-05 - val_loss: 1.9215e-04 - val_mean: 1.9215e-04\n","Epoch 48/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.3578e-05 - mean: 7.3578e-05 - val_loss: 1.8964e-04 - val_mean: 1.8966e-04\n","Epoch 49/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.0439e-05 - mean: 7.0439e-05 - val_loss: 1.8448e-04 - val_mean: 1.8448e-04\n","Epoch 50/50\n","586/586 [==============================] - 10s 16ms/step - loss: 6.7682e-05 - mean: 6.7682e-05 - val_loss: 1.8233e-04 - val_mean: 1.8231e-04\n","782/782 [==============================] - 3s 4ms/step - loss: 1.8215e-04 - mean: 1.8219e-04\n","Final MSE on test data: 0.0001821500190999359\n","writing to files\n","782/782 [==============================] - 3s 3ms/step\n","file writing done\n","Epoch 1/50\n","586/586 [==============================] - 15s 18ms/step - loss: 0.2501 - mean: 0.2501 - val_loss: 0.0226 - val_mean: 0.0226\n","Epoch 2/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0142 - mean: 0.0142 - val_loss: 0.0099 - val_mean: 0.0099\n","Epoch 3/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0077 - mean: 0.0077 - val_loss: 0.0065 - val_mean: 0.0065\n","Epoch 4/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0054 - mean: 0.0054 - val_loss: 0.0050 - val_mean: 0.0050\n","Epoch 5/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0042 - mean: 0.0042 - val_loss: 0.0040 - val_mean: 0.0040\n","Epoch 6/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0033 - mean: 0.0033 - val_loss: 0.0034 - val_mean: 0.0034\n","Epoch 7/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0027 - mean: 0.0027 - val_loss: 0.0028 - val_mean: 0.0028\n","Epoch 8/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0022 - mean: 0.0022 - val_loss: 0.0025 - val_mean: 0.0025\n","Epoch 9/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0019 - mean: 0.0019 - val_loss: 0.0021 - val_mean: 0.0021\n","Epoch 10/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0016 - mean: 0.0016 - val_loss: 0.0020 - val_mean: 0.0020\n","Epoch 11/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0014 - mean: 0.0014 - val_loss: 0.0018 - val_mean: 0.0018\n","Epoch 12/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0013 - mean: 0.0013 - val_loss: 0.0016 - val_mean: 0.0016\n","Epoch 13/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0016 - val_mean: 0.0016\n","Epoch 14/50\n","586/586 [==============================] - 10s 16ms/step - loss: 0.0011 - mean: 0.0011 - val_loss: 0.0015 - val_mean: 0.0015\n","Epoch 15/50\n","586/586 [==============================] - 10s 17ms/step - loss: 0.0010 - mean: 0.0010 - val_loss: 0.0014 - val_mean: 0.0014\n","Epoch 16/50\n","586/586 [==============================] - 10s 17ms/step - loss: 9.7378e-04 - mean: 9.7379e-04 - val_loss: 0.0014 - val_mean: 0.0014\n","Epoch 17/50\n","586/586 [==============================] - 10s 16ms/step - loss: 9.3381e-04 - mean: 9.3382e-04 - val_loss: 0.0013 - val_mean: 0.0013\n","Epoch 18/50\n","586/586 [==============================] - 10s 16ms/step - loss: 8.9332e-04 - mean: 8.9332e-04 - val_loss: 0.0013 - val_mean: 0.0013\n","Epoch 19/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.4341e-04 - mean: 8.4342e-04 - val_loss: 0.0012 - val_mean: 0.0012\n","Epoch 20/50\n","586/586 [==============================] - 10s 17ms/step - loss: 7.7541e-04 - mean: 7.7541e-04 - val_loss: 0.0011 - val_mean: 0.0011\n","Epoch 21/50\n","586/586 [==============================] - 10s 16ms/step - loss: 7.0034e-04 - mean: 7.0034e-04 - val_loss: 9.6418e-04 - val_mean: 9.6420e-04\n","Epoch 22/50\n","586/586 [==============================] - 10s 17ms/step - loss: 6.2424e-04 - mean: 6.2424e-04 - val_loss: 8.6916e-04 - val_mean: 8.6913e-04\n","Epoch 23/50\n","586/586 [==============================] - 10s 17ms/step - loss: 5.5383e-04 - mean: 5.5383e-04 - val_loss: 7.8647e-04 - val_mean: 7.8657e-04\n","Epoch 24/50\n","586/586 [==============================] - 10s 16ms/step - loss: 4.8606e-04 - mean: 4.8607e-04 - val_loss: 7.0968e-04 - val_mean: 7.0968e-04\n","Epoch 25/50\n","586/586 [==============================] - 10s 17ms/step - loss: 4.3174e-04 - mean: 4.3174e-04 - val_loss: 6.4493e-04 - val_mean: 6.4502e-04\n","Epoch 26/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.7978e-04 - mean: 3.7978e-04 - val_loss: 5.7853e-04 - val_mean: 5.7853e-04\n","Epoch 27/50\n","586/586 [==============================] - 10s 17ms/step - loss: 3.3702e-04 - mean: 3.3702e-04 - val_loss: 5.2912e-04 - val_mean: 5.2910e-04\n","Epoch 28/50\n","586/586 [==============================] - 10s 16ms/step - loss: 3.0119e-04 - mean: 3.0119e-04 - val_loss: 4.8655e-04 - val_mean: 4.8668e-04\n","Epoch 29/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.7175e-04 - mean: 2.7175e-04 - val_loss: 4.4152e-04 - val_mean: 4.4151e-04\n","Epoch 30/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.4464e-04 - mean: 2.4463e-04 - val_loss: 4.1354e-04 - val_mean: 4.1352e-04\n","Epoch 31/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.2103e-04 - mean: 2.2103e-04 - val_loss: 3.8350e-04 - val_mean: 3.8350e-04\n","Epoch 32/50\n","586/586 [==============================] - 10s 17ms/step - loss: 2.0053e-04 - mean: 2.0053e-04 - val_loss: 3.5620e-04 - val_mean: 3.5627e-04\n","Epoch 33/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.8248e-04 - mean: 1.8248e-04 - val_loss: 3.3743e-04 - val_mean: 3.3744e-04\n","Epoch 34/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.6707e-04 - mean: 1.6707e-04 - val_loss: 3.1427e-04 - val_mean: 3.1434e-04\n","Epoch 35/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.5461e-04 - mean: 1.5461e-04 - val_loss: 2.9689e-04 - val_mean: 2.9697e-04\n","Epoch 36/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.4273e-04 - mean: 1.4273e-04 - val_loss: 2.8231e-04 - val_mean: 2.8242e-04\n","Epoch 37/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.3150e-04 - mean: 1.3150e-04 - val_loss: 2.6488e-04 - val_mean: 2.6496e-04\n","Epoch 38/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.2178e-04 - mean: 1.2178e-04 - val_loss: 2.5125e-04 - val_mean: 2.5125e-04\n","Epoch 39/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.1389e-04 - mean: 1.1389e-04 - val_loss: 2.4114e-04 - val_mean: 2.4122e-04\n","Epoch 40/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.0672e-04 - mean: 1.0672e-04 - val_loss: 2.3467e-04 - val_mean: 2.3474e-04\n","Epoch 41/50\n","586/586 [==============================] - 10s 17ms/step - loss: 1.0034e-04 - mean: 1.0034e-04 - val_loss: 2.2432e-04 - val_mean: 2.2438e-04\n","Epoch 42/50\n","586/586 [==============================] - 10s 17ms/step - loss: 9.3938e-05 - mean: 9.3938e-05 - val_loss: 2.1516e-04 - val_mean: 2.1518e-04\n","Epoch 43/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.8929e-05 - mean: 8.8929e-05 - val_loss: 2.0718e-04 - val_mean: 2.0724e-04\n","Epoch 44/50\n","586/586 [==============================] - 10s 17ms/step - loss: 8.3739e-05 - mean: 8.3739e-05 - val_loss: 2.0412e-04 - val_mean: 2.0422e-04\n","Epoch 45/50\n","586/586 [==============================] - 10s 17ms/step - loss: 7.9648e-05 - mean: 7.9648e-05 - val_loss: 1.9634e-04 - val_mean: 1.9648e-04\n","Epoch 46/50\n","586/586 [==============================] - 10s 17ms/step - loss: 7.5936e-05 - mean: 7.5936e-05 - val_loss: 1.9049e-04 - val_mean: 1.9059e-04\n","Epoch 47/50\n","586/586 [==============================] - 10s 17ms/step - loss: 7.1766e-05 - mean: 7.1766e-05 - val_loss: 1.8537e-04 - val_mean: 1.8547e-04\n","Epoch 48/50\n","586/586 [==============================] - 10s 17ms/step - loss: 6.7589e-05 - mean: 6.7589e-05 - val_loss: 1.7948e-04 - val_mean: 1.7955e-04\n","Epoch 49/50\n","586/586 [==============================] - 10s 17ms/step - loss: 6.4417e-05 - mean: 6.4417e-05 - val_loss: 1.7523e-04 - val_mean: 1.7533e-04\n","Epoch 50/50\n","586/586 [==============================] - 10s 17ms/step - loss: 6.2238e-05 - mean: 6.2238e-05 - val_loss: 1.7246e-04 - val_mean: 1.7247e-04\n","782/782 [==============================] - 3s 4ms/step - loss: 1.7041e-04 - mean: 1.7038e-04\n","Final MSE on test data: 0.00017040933016687632\n","writing to files\n","782/782 [==============================] - 3s 3ms/step\n","file writing done\n"]}],"source":["for snrdb in snr_dB:\n","    # data set has stacked A's and y's if dual_bs\n","    if dual_bs:\n","      # create sensing matrix A - will stack so energy of col of A = 1/2\n","      A = np.sqrt(1/(4*n))*np.random.randn(n, N) + 1j*np.sqrt(1/(4*n))*np.random.randn(n, N)  \n","    else:\n","      A = np.sqrt(1/(2*n))*np.random.randn(n, N) + 1j*np.sqrt(1/(2*n))*np.random.randn(n, N)  \n","      \n","    if fading:\n","      h1 = np.sqrt(1/2)*np.random.randn(N) + 1j*np.sqrt(1/2)*np.random.randn(N) \n","      h1 = np.diag(h1) \n","      \n","      A1 = A @ h1\n","\n","      if dual_bs:\n","        # now stack and make one A\n","        h2 = np.sqrt(1/2)*np.random.randn(N) + 1j*np.sqrt(1/2)*np.random.randn(N) \n","        h2 = np.diag(h2) \n","        \n","        A2 = A @ h2\n","        A = np.vstack((A1, A2))\n","      else:\n","        A = A1\n","        \n","    elif dual_bs: # no fading, 2 BS\n","      # A is just stacked with itself if no fading -- will get overwritten if fading\n","      A = np.vstack((A,A))\n","      \n","\n","\n","    # creates the appropiate sigma\n","    if dual_bs:\n","      snr = (10**(snrdb/10))*2*n\n","    else:\n","      snr = (10**(snrdb/10))*n\n","    sigma = 1/(np.sqrt(snr))\n","\n","\n","    # noise vectors\n","    w1 = []\n","    for i in range(total_num_samples):\n","      w1.append(np.sqrt((sigma**2)/2) * np.random.randn(n) + 1j*np.sqrt((sigma**2)/2) * np.random.randn(n))\n","    w1 = np.array(w1)\n","\n","    if dual_bs:\n","      w2 = []\n","      for i in range(total_num_samples):\n","        w2.append(np.sqrt((sigma**2)/2) * np.random.randn(n) + 1j*np.sqrt((sigma**2)/2) * np.random.randn(n))\n","      w2 = np.array(w2)\n","      # stack the noise\n","      w = np.hstack((w1,w2))\n","    else:\n","      w = w1\n","\n","    # inital alpha value\n","    init_alpha = 0.3\n","\n","    # creating initial values for trainable parameters\n","    _, Lambda, _ = np.linalg.svd(A)\n","    L = np.max(Lambda) + 1\n","\n","    init_Q = np.eye(N) - (A.T @ A) / L\n","    init_W = A / L\n","\n","    # create data\n","    x = np.zeros((total_num_samples, N))\n","    idx_nonzero = rng.permuted(np.tile(np.arange(N), (total_num_samples, 1)), axis=1)\n","    for i in range(k):\n","      x[np.arange(total_num_samples), idx_nonzero[:, i].flatten()] = 1\n","\n","      \n","    if noise:\n","      y = x @ A.T + w  # adding noise here\n","    else:\n","      y = x @ A.T\n","    y = np.hstack((np.zeros((total_num_samples, N)), y))\n","\n","    # Divide data into training, validation, testing sets\n","    train_data = y[0:num_train_samples, :]\n","    train_labels = x[0:num_train_samples, :]\n","    valid_data = y[num_train_samples:num_train_samples+num_valid_samples, :]\n","    valid_labels = x[num_train_samples:num_train_samples+num_valid_samples, :]\n","    test_data = y[num_train_samples+num_valid_samples:, :]\n","    test_labels = x[num_train_samples+num_valid_samples:, :]\n"," ########################################################\n","    lista_mse_cmplx = []\n","    learn_rate = .0001\n","    op = keras.optimizers.Adam(learning_rate=learn_rate)\n","\n","    #epoch_nums = [20,20,20,20,20,20,22,25,28,31,34,40,43,46,50]\n","    epochs = 50\n","\n","    if dual_bs:\n","    # create initial input -- shape is now (2n + N)\n","        input = keras.layers.Input(shape=(2*n+N,), name='y_inputs',dtype='complex64')\n","    else:\n","        input = keras.layers.Input(shape=(n+N,), name='y_inputs',dtype='complex64')\n","\n","    for idx_layer in range(num_layers):\n","      # calls the layer differently depending on what layer it is \n","        if idx_layer == 0:\n","          x_hidden = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (input)\n","        elif idx_layer == num_layers - 1:  # output is populated on the last layer\n","          output = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (x_hidden)\n","        else:\n","          x_hidden = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (x_hidden)\n","\n","\n","    model = keras.Model(inputs=input, outputs=output, name='CRF_LISTAModel')\n","    # compile keras model\n","    custom_mse_loss = CustomMSELoss(N)\n","    custom_mse_metric = CustomMSEMetric(N)\n","    model.compile(optimizer=op, loss=custom_mse_loss, metrics=[custom_mse_metric])\n","\n","    # train model\n","    history = model.fit(train_data,\n","                train_labels,\n","                batch_size=128,\n","                epochs=epochs,\n","                validation_data=(valid_data, valid_labels))\n","\n","    results = model.evaluate(test_data, test_labels)\n","    lista_mse_cmplx.append(results[0])\n","    print(f'Final MSE on test data: {results[0]}')\n","\n","    ## find MD, FA ##\n","    print('writing to files')\n","    xHt = model.predict(test_data)\n","    np.save('2bs_snr'+str(snrdb)+'dB_mdfa_predictions.npy', xHt)\n","\n","    x = test_labels\n","    np.save('2bs_snr'+str(snrdb)+'dB_mdfa_labels.npy',x)\n","    print('file writing done')\n"]},{"cell_type":"markdown","metadata":{"id":"5aXVOcfzmWKj"},"source":["# MD, FA"]},{"cell_type":"code","source":["!cp '2bs_snr-12dB_mdfa_predictions.npy' /content/drive/MyDrive/Research\n","!cp '2bs_snr-12dB_mdfa_labels.npy' /content/drive/MyDrive/Research"],"metadata":{"id":"I3Jr3Y5C8g8a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":186301,"status":"ok","timestamp":1680193702356,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"},"user_tz":300},"id":"EaCShW10QqeN","outputId":"d6660aa3-7920-4a91-8b3b-88ccae434fb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Threshold: 0.1\n","FA: [10.706184738955823, 7.035863453815261, 1.620562248995984, 0.5329317269076306, 0.13658634538152611, 0.05164658634538152, 0.05397590361445783]\n","MD: [1.829839357429719, 0.9695582329317269, 0.07542168674698795, 0.02855421686746988, 0.0008433734939759036, 0.0, 0.0024096385542168677]\n","Threshold: 0.15000000000000002\n","FA: [7.082329317269076, 4.463413654618474, 0.8473092369477911, 0.24911646586345382, 0.04863453815261044, 0.013534136546184738, 0.017791164658634537]\n","MD: [2.1894779116465863, 1.1813253012048193, 0.101285140562249, 0.038795180722891565, 0.0017269076305220883, 0.0, 0.004497991967871486]\n","Threshold: 0.20000000000000004\n","FA: [4.814939759036145, 2.9366265060240964, 0.4727710843373494, 0.12164658634538153, 0.018714859437751002, 0.0034538152610441766, 0.006345381526104418]\n","MD: [2.5970682730923693, 1.425301204819277, 0.1355421686746988, 0.05096385542168675, 0.0026104417670682733, 0.0, 0.007911646586345382]\n","Threshold: 0.25000000000000006\n","FA: [3.32285140562249, 1.9696787148594377, 0.2714859437751004, 0.06293172690763052, 0.00714859437751004, 0.0009638554216867469, 0.0018875502008032128]\n","MD: [3.0670281124497993, 1.71570281124498, 0.18060240963855423, 0.06654618473895582, 0.003895582329317269, 0.0, 0.012449799196787148]\n","Threshold: 0.30000000000000004\n","FA: [2.3185140562249, 1.3315261044176707, 0.15771084337349398, 0.03204819277108434, 0.0030923694779116466, 0.000321285140562249, 0.0006827309236947791]\n","MD: [3.6106024096385543, 2.057831325301205, 0.23417670682730923, 0.08248995983935743, 0.0059036144578313255, 0.00020080321285140563, 0.01751004016064257]\n","Threshold: 0.3500000000000001\n","FA: [1.6214056224899598, 0.8983534136546185, 0.09244979919678716, 0.016184738955823293, 0.0011244979919678715, 0.0, 0.0001606425702811245]\n","MD: [4.241927710843373, 2.472168674698795, 0.30329317269076306, 0.10168674698795181, 0.00891566265060241, 0.0007630522088353413, 0.02461847389558233]\n","Threshold: 0.40000000000000013\n","FA: [1.141566265060241, 0.6076706827309237, 0.053413654618473895, 0.00819277108433735, 0.0005220883534136547, 0.0, 0.00012048192771084337]\n","MD: [4.975582329317269, 2.9644578313253014, 0.394859437751004, 0.12815261044176707, 0.01281124497991968, 0.0014457831325301205, 0.03465863453815261]\n","Threshold: 0.45000000000000007\n","FA: [0.8089156626506024, 0.4123694779116466, 0.032369477911646585, 0.004096385542168675, 0.00028112449799196787, 0.0, 0.0]\n","MD: [5.840240963855422, 3.5708032128514056, 0.5244176706827309, 0.161285140562249, 0.019156626506024097, 0.0036947791164658635, 0.046586345381526104]\n","Threshold: 0.5000000000000001\n","FA: [0.5740963855421687, 0.283855421686747, 0.01955823293172691, 0.0022088353413654616, 4.0160642570281125e-05, 0.0, 0.0]\n","MD: [6.849397590361446, 4.330602409638554, 0.7061445783132531, 0.20602409638554217, 0.029518072289156625, 0.006907630522088353, 0.059357429718875504]\n","Threshold: 0.5500000000000002\n","FA: [0.4034136546184739, 0.1893574297188755, 0.010923694779116465, 0.001325301204819277, 0.0, 0.0, 0.0]\n","MD: [8.03281124497992, 5.255502008032129, 0.9659839357429719, 0.26714859437751004, 0.04417670682730924, 0.013855421686746987, 0.07710843373493977]\n","Threshold: 0.6000000000000002\n","FA: [0.28393574297188756, 0.12967871485943774, 0.005823293172690763, 0.0008433734939759036, 0.0, 0.0, 0.0]\n","MD: [9.390923694779117, 6.388072289156627, 1.349437751004016, 0.357429718875502, 0.06975903614457832, 0.0257429718875502, 0.09594377510040161]\n","Threshold: 0.6500000000000001\n","FA: [0.2008835341365462, 0.08718875502008032, 0.0033734939759036144, 0.00024096385542168674, 0.0, 0.0, 0.0]\n","MD: [10.948353413654619, 7.795502008032129, 1.9403614457831326, 0.49779116465863454, 0.11530120481927711, 0.04694779116465864, 0.12136546184738956]\n","Threshold: 0.7000000000000002\n","FA: [0.14140562248995983, 0.06108433734939759, 0.0018875502008032128, 8.032128514056225e-05, 0.0, 0.0, 0.0]\n","MD: [12.69710843373494, 9.497590361445782, 2.856144578313253, 0.7407630522088353, 0.197429718875502, 0.08092369477911647, 0.1521686746987952]\n","Threshold: 0.7500000000000002\n","FA: [0.09967871485943774, 0.040843373493975904, 0.0005622489959839357, 4.0160642570281125e-05, 0.0, 0.0, 0.0]\n","MD: [14.650682730923695, 11.499277108433734, 4.290441767068273, 1.192971887550201, 0.3553012048192771, 0.14779116465863454, 0.20309236947791165]\n","Threshold: 0.8000000000000002\n","FA: [0.068714859437751, 0.027309236947791166, 0.00020080321285140563, 4.0160642570281125e-05, 0.0, 0.0, 0.0]\n","MD: [16.769156626506025, 13.817991967871485, 6.454698795180723, 2.115421686746988, 0.7372690763052209, 0.29477911646586347, 0.2877911646586345]\n","Threshold: 0.8500000000000002\n","FA: [0.047751004016064254, 0.019076305220883535, 8.032128514056225e-05, 4.0160642570281125e-05, 0.0, 0.0, 0.0]\n","MD: [19.053534136546183, 16.436184738955824, 9.558192771084338, 4.087751004016064, 1.8152610441767068, 0.7315261044176706, 0.5273895582329318]\n","Threshold: 0.9000000000000002\n","FA: [0.03220883534136546, 0.013092369477911647, 4.0160642570281125e-05, 4.0160642570281125e-05, 0.0, 0.0, 0.0]\n","MD: [21.391807228915663, 19.275060240963857, 13.656184738955822, 8.033132530120483, 4.948915662650602, 2.5840562248995984, 1.7876305220883535]\n","Threshold: 0.9500000000000003\n","FA: [0.022289156626506025, 0.008755020080321285, 0.0, 4.0160642570281125e-05, 0.0, 0.0, 0.0]\n","MD: [23.740481927710842, 22.194698795180724, 18.58309236947791, 14.55289156626506, 12.204899598393574, 9.553253012048193, 8.168634538152611]\n"]}],"source":["# determining threshold based on 24,900 test samples\n","test_to = 24900\n","thresholds = np.arange(.1,1,.05)\n","\n","for threshold in thresholds:\n","  avg_fa = []\n","  avg_md = []\n","  for snrdb in snr_dB:\n","    # load in data from the files\n","    # xHt = np.load('2bs_snr'+str(snrdb)+'dB_mdfa_predictions.npy')\n","    name = \"/content/drive/MyDrive/Research/2bs_snr\"+str(snrdb)+\"dB_mdfa_predictions.npy\"\n","    xHt = np.load(name)\n","    xHt = xHt.T[:N,:]\n","    xHt = xHt.T\n","    label = '/content/drive/MyDrive/Research/2bs_snr'+str(snrdb)+'dB_mdfa_labels.npy'\n","    labels = np.load(label)\n","\n","    # find the avg MD FA\n","    fa_ar = np.zeros(test_to)\n","    md_ar = np.zeros(test_to)\n","    for i in range(test_to):\n","        user_guess = np.where(abs(xHt[i]) > threshold)\n","        real_users = np.where(abs(labels[i]) == 1)\n","        # print(f'user_guess: {user_guess}')\n","        # print(f'real: {real_users}')\n","        fa_ar[i] = len(np.setdiff1d(user_guess, real_users))\n","        md_ar[i] = len(np.setdiff1d(real_users, user_guess))\n","    # find the avg\n","    avg_fa.append(sum(fa_ar) / test_to)\n","    avg_md.append(sum(md_ar) / test_to)\n","  print(f'Threshold: {threshold}')\n","  print(f'FA: {avg_fa}')\n","  print(f'MD: {avg_md}')"]},{"cell_type":"code","source":["threshold = .45  # change me based on results above\n","\n","avg_fa =[]\n","avg_md=[]\n","# now test on the remaining 100 samples\n","for snrdb in snr_dB:\n","  name = \"/content/drive/MyDrive/Research/2bs_snr\"+str(snrdb)+\"dB_mdfa_predictions.npy\"\n","  xHt = np.load(name)\n","  xHt = xHt.T[:N,:]\n","  xHt = xHt.T\n","  label = '/content/drive/MyDrive/Research/2bs_snr'+str(snrdb)+'dB_mdfa_labels.npy'\n","  labels = np.load(label)\n","\n","  # find the avg MD FA\n","  fa_ar = np.zeros(100)\n","  md_ar = np.zeros(100)\n","  cnt=0\n","  for i in range(test_to, num_test_samples):\n","    user_guess = np.where(abs(xHt[i]) > threshold)\n","    real_users = np.where(abs(labels[i]) == 1)\n","    fa_ar[cnt] = len(np.setdiff1d(user_guess, real_users))\n","    md_ar[cnt] = len(np.setdiff1d(real_users, user_guess))\n","    cnt+=1\n","  # find the avg\n","  avg_fa.append(sum(fa_ar) / 100)\n","  avg_md.append(sum(md_ar) / 100)\n","\n","print(f'Threshold: {threshold}')\n","print(f'FA: {avg_fa}')\n","print(f'MD: {avg_md}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5ocgleQNggU","executionInfo":{"status":"ok","timestamp":1680193822671,"user_tz":300,"elapsed":8934,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"}},"outputId":"7b0eddb3-61d7-4886-a459-e6c548e8613e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Threshold: 0.45\n","FA: [0.78, 0.39, 0.04, 0.01, 0.0, 0.0, 0.0]\n","MD: [5.76, 3.69, 0.65, 0.12, 0.0, 0.01, 0.06]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1680063160245,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"},"user_tz":300},"id":"S070GtJERZ8X","outputId":"7b123871-a51b-4048-878d-347ca0836cd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["2 BS. CRF. threshold: 0.8\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# plot the results\n","total_er =[]\n","for i in range(len(avg_fa)):\n","  total_er.append(avg_fa[i] + avg_md[i])\n","print(f\"2 BS. CRF. threshold: {threshold}\")\n","plt.figure()\n","plt.plot(snr_dB, avg_fa, label=\"FA - 2 BS\", linestyle=\"dashed\")\n","plt.plot(snr_dB, avg_md, label=\"MD - 2 BS\")\n","plt.plot(snr_dB, total_er, label='total errors - 2 BS', linestyle='dotted')\n","plt.legend()\n","plt.title(\"MD, FA vs. SNR\")\n","plt.xlabel(\"SNR(dB)\")\n","plt.ylabel(\"Number of MD, FA\")\n","plt.grid(True, which ='both')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1680063198121,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"},"user_tz":300},"id":"YWC4InEukaWl","outputId":"c647ad25-0ac2-456b-f327-22c4a2c1a276"},"outputs":[{"name":"stdout","output_type":"stream","text":["FA: [1.3806, 0.6454, 0.26368, 0.19968, 0.20888, 0.14884, 0.16292]\n","MD: [17.17332, 13.89032, 6.88492, 1.84348, 0.69424, 0.20204, 0.15432]\n"]}],"source":["print(f'FA: {avg_fa}')\n","print(f'MD: {avg_md}')"]},{"cell_type":"code","source":["for snrdb in snr_dB:\n","  cnt = 0\n","  # load in data from the files\n","  name = \"/content/drive/MyDrive/Research/2bs_snr\"+str(snrdb)+\"dB_mdfa_predictions.npy\"\n","  xHt = np.load(name)\n","  \n","  for i in range(num_test_samples):\n","    cnt += len(np.where(abs(xHt[i])!=0))\n","  print(f'SNR: {snrdb}', end=\" \")\n","  print(cnt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RkjtJggJs7v","executionInfo":{"status":"ok","timestamp":1680191012303,"user_tz":300,"elapsed":32114,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"}},"outputId":"8d55c35a-3adf-4ff3-e648-248f568e2f50"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["SNR: -12 25000\n","SNR: -10 25000\n","SNR: -5 25000\n","SNR: 1 25000\n","SNR: 5 25000\n","SNR: 10 25000\n","SNR: 20 25000\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":13,"status":"error","timestamp":1680062816704,"user":{"displayName":"Holly Roper","userId":"12327319719582283021"},"user_tz":300},"id":"d20di1l2esWb","outputId":"a9f1cb54-ddb6-4747-9ca9-053e98a750e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["xHT: 1.0869171619415283\n","x: 1.0\n","xHT: 0.4645974040031433\n","x: 1.0\n","xHT: 1.0864770412445068\n","x: 1.0\n","xHT: 0.9816107749938965\n","x: 1.0\n","xHT: 0.9946898221969604\n","x: 1.0\n","xHT: 1.0476610660552979\n","x: 1.0\n","xHT: 0.8737512230873108\n","x: 1.0\n","xHT: 0.7667049169540405\n","x: 1.0\n","xHT: 0.7084980010986328\n","x: 1.0\n","xHT: 1.097817063331604\n","x: 1.0\n","xHT: 0.9668179750442505\n","x: 1.0\n","xHT: 0.8027741312980652\n","x: 1.0\n","xHT: 0.6940854787826538\n","x: 1.0\n","xHT: 0.8723172545433044\n","x: 1.0\n","xHT: 0.4168062210083008\n","x: 1.0\n","xHT: 1.0143219232559204\n","x: 1.0\n","xHT: 1.0996824502944946\n","x: 1.0\n","xHT: 0.06346434354782104\n","x: 1.0\n","xHT: 1.0880072116851807\n","x: 1.0\n","xHT: 0.7190245985984802\n","x: 1.0\n","xHT: 1.0463718175888062\n","x: 1.0\n","xHT: 1.2471866607666016\n","x: 1.0\n","xHT: 1.2560244798660278\n","x: 1.0\n","xHT: 0.9082379341125488\n","x: 1.0\n","xHT: 0.31492286920547485\n","x: 1.0\n","xHT: 1.0275596380233765\n","x: 1.0\n","xHT: 0.8204786777496338\n","x: 1.0\n","xHT: 0.9176888465881348\n","x: 1.0\n","xHT: 0.9241503477096558\n","x: 1.0\n","xHT: 1.415587067604065\n","x: 1.0\n","xHT: 0.3831958770751953\n","x: 1.0\n","xHT: 0.7402455806732178\n","x: 1.0\n","xHT: 0.9005430936813354\n","x: 1.0\n","xHT: 0.9972933530807495\n","x: 1.0\n","xHT: 1.2419475317001343\n","x: 1.0\n","xHT: 1.6030620336532593\n","x: 1.0\n","xHT: 0.8618197441101074\n","x: 1.0\n","xHT: 1.1773542165756226\n","x: 1.0\n","xHT: 0.8813405632972717\n","x: 1.0\n","xHT: 1.068987488746643\n","x: 1.0\n"]},{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-97a7e7963c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2bs_snr-10dB_mdfa_labels.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxHt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mxHt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'xHT: {abs(xHt[6][elm])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'x: {abs(labels[6][elm])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 1024 is out of bounds for axis 0 with size 1024"]}],"source":["xHt = np.load('2bs_snr-10dB_mdfa_predictions.npy')\n","labels = np.load('2bs_snr-10dB_mdfa_labels.npy')\n","for elm in range(len(xHt[6])-1):\n","  if xHt[6][elm] != 0 and labels[6][elm] != 0:\n","    print(f'xHT: {abs(xHt[6][elm])}')\n","    print(f'x: {abs(labels[6][elm])}')\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QlDdzv0_gy_H"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"150DdoeKqsia7jMItMqzj8hFooy3Fwodi","authorship_tag":"ABX9TyMMvZo3LqPM5bqY5Yz3w6UH"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}