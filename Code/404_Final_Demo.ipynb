{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAbFOnd2M7w1ENwjOv1M/J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9T-CSzXgy23Z"},"outputs":[],"source":["import numpy as np\n","import tensorflow.keras as keras\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import random"]},{"cell_type":"markdown","source":["# Equations"],"metadata":{"id":"a-QKfcWz5Kzf"}},{"cell_type":"markdown","source":["Iterative Soft Thresholding can be defined by the following update equation:\n","\n","\\begin{equation}\n","    \\mathbf{x^{l+1}} = \\eta((\\mathbf{I} - \\frac{1}{L}\\mathbf{A^T}\\mathbf{A})\\mathbf{x^l} + \\frac{1}{L}\\mathbf{A^T}\\mathbf{y})\n","\\end{equation}\n","\n","The Eta function: \\begin{equation}    \\eta(u;T) = \n","    \\left\\{\n","    \\begin{array}{lr}\n","        u - T &\\text{if } u \\ge T \\\\\n","        u + T &\\text{if } u \\le -T \\\\\n","        0 &\\text{else}&\n","    \\end{array}\n","    \\right. \\end{equation}"],"metadata":{"id":"h5wNQsGJ5Mjh"}},{"cell_type":"markdown","source":["For Approximate Message Passing The residual error is calculated by:\n","\n","\\begin{equation}\n","    \\mathbf{z}^t = \\mathbf{y}-\\mathbf{Ax}^t + \\frac{1}{2\\delta}z^{t-1}(\\langle\\frac{\\partial\\eta^{R}}{\\partial x_R}(x^{t-1}+A^Hz^{t-1};\\lambda^{t-1})\\rangle+\\langle\\frac{\\partial\\eta^I}{\\partial x_I}(x^{t-1}+A^Hz^{t-1};\\lambda^{t-1})\\rangle)\n","\\end{equation}\n","\n","\n","\n","The denoising/thresholding function differs from the one used in ISTA and is shown below.\n","\n","\\begin{equation}\n","    \\eta(u+iv;\\lambda) = (u+iv-\\frac{\\lambda(u+iv)}{\\sqrt{u^2+v^2}})\\mathbb{I}_{\\{u^2+v^2\\geq \\lambda\\}}\n","\\end{equation}\n","\n","and\n","\n","\\begin{equation}\n","    \\langle\\eta'(\\alpha;\\lambda)\\rangle = \\frac{\\sum_{i=1}^N \\eta'(\\alpha_i;\\lambda)}{N}\n","\\end{equation}\n","\n","The estimate of $\\mathbf{x}$ can then be computed as follows\n","\n","\\begin{equation}\n","    \\mathbf{x}^{t+1} = \\eta(\\mathbf{x}^t+\\mathbf{A}^H\\mathbf{z}^t;\\lambda^t).\n","\\end{equation}"],"metadata":{"id":"57YOp5lw5jiu"}},{"cell_type":"markdown","source":["# Shared Functions"],"metadata":{"id":"PKnOmBNmy_nh"}},{"cell_type":"code","source":["# the thresholding function used in ISTA\n","# also used for real valued AMP\n","def eta(u, T, cmplx):\n","  # keeps the angle the same and reduces the magnitude\n","  if cmplx:\n","    return np.exp(1j*np.angle(u)) * (np.maximum(np.abs(u)-T, 0))\n","  else:\n","      return (u - T)*(u >= T) + (u + T)*(u <= -T)"],"metadata":{"id":"z61Xf4cx3cvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# used to generate data for ISTA and AMP\n","def make_data(sys_param, tfs):\n","  '''sys_param contains: n,N,k,sigma\n","  tfs (true/false) contains: noise, fading, dual_bs, cmplx\n","    noise is boolean, true if noise\n","    fading is boolean, true if fading; fading is real or complex depending on the value of cmplx\n","    sigma is the variance of the noise given\n","    dual_bs is a boolean, true for 2 BS case\n","    cmplx is boolean, true if it wants complex values\n","    returns A_1, A_2, x_uL, y_uL1, y_uL2, L1, L2\n","    if it is a single base station then the unneeded values will be returned as zero\n","    '''\n","\n","    # unwrap the arguments\n","    n, N, k, sigma = sys_param\n","    noise, fading, dual_bs, cmplx = tfs\n","    \n","    # creates the x-vector with k-nonzero entries\n","    x_uL = np.zeros((N, 1), dtype=np.complex_)\n","    idx_nonzero_entries = np.random.permutation(N)[0:k]\n","    x_uL[idx_nonzero_entries] = 1\n","\n","    # if there's two base stations, these values will be overridden\n","    A_2 = 0\n","    L2 = 0\n","    y_uL2 = 0\n","\n","    if cmplx:  # complex single BS\n","        # sensing matrices\n","        A_1 = np.sqrt(1 / (2 * n)) * np.random.randn(n, N) + 1j * np.sqrt(1 / (2 * n)) * np.random.randn(n, N)\n","        # finding thresholding parameter\n","        _, Lambda1, _ = np.linalg.svd(A_1)\n","        L1 = np.max(Lambda1) + 1\n","        # creating complex noise\n","        w1 = np.sqrt((sigma ** 2) / 2) * np.random.randn(n).reshape(-1, 1) + 1j * np.sqrt(\n","            (sigma ** 2) / 2) * np.random.randn(n).reshape(-1, 1)\n","\n","        if dual_bs:  # create second pair of matrices\n","            A_1 = np.sqrt(1 / (4 * n)) * np.random.randn(n, N) + 1j * np.sqrt(1 / (4 * n)) * np.random.randn(n, N)\n","            A_2 = A_1.copy()\n","            _, Lambda1, _ = np.linalg.svd(A_1)\n","            L1 = np.max(Lambda1) + 1\n","            L2 = L1\n","            w2 = np.sqrt((sigma ** 2) / 2) * np.random.randn(n).reshape(-1, 1) + 1j * np.sqrt(\n","                (sigma ** 2) / 2) * np.random.randn(n).reshape(-1, 1)\n","\n","        if fading:  # complex fading\n","            # creating fading effects -> CN(0,1)\n","            h_uL1 = np.sqrt(1 / 2) * np.random.random(N) + np.sqrt(1 / 2) * 1j * np.random.random(N)\n","            h_uL1 = np.diag(h_uL1)\n","            # sensing matrix with fading applied\n","            A_1 = A_1 @ h_uL1\n","            # finding thresholding parameter\n","            _, Lambda1, _ = np.linalg.svd(A_1)\n","            L1 = np.max(Lambda1) + 1\n","\n","            if noise:  # single BS, complex fading and noise\n","                y_uL1 = A_1 @ x_uL + w1\n","            else:\n","                y_uL1 = A_1 @ x_uL\n","\n","            if dual_bs:  # complex fading, 2 BS\n","                # create second set of fading\n","                # creating fading effects -> CN(0,1)\n","                h_uL2 = np.sqrt(1 / 2) * np.random.random(N) + np.sqrt(1 / 2) * 1j * np.random.random(N)\n","                h_uL2 = np.diag(h_uL2)\n","                # sensing matrix with fading applied\n","                A_2 = A_2 @ h_uL2\n","                # finding thresholding parameter\n","                _, Lambda1, _ = np.linalg.svd(A_2)\n","                L2 = np.max(Lambda1) + 1\n","\n","                if noise: \n","                    y_uL2 = A_2 @ x_uL + w2\n","                else:\n","                    y_uL2 = A_2 @ x_uL\n","\n","        else:  # complex, no fading\n","            if noise:\n","                y_uL1 = A_1 @ x_uL + w1\n","            else:\n","                y_uL1 = A_1 @ x_uL\n","\n","            if dual_bs: \n","                if noise:\n","                    y_uL2 = A_2 @ x_uL + w2\n","                else:\n","                    y_uL2 = A_2 @ x_uL\n","\n","    else:  # real valued\n","        # sensing matrices\n","        A_1 = np.sqrt(1 / n) * np.random.randn(n, N)\n","        # finding thresholding parameter\n","        _, Lambda1, _ = np.linalg.svd(A_1)\n","        L1 = np.max(Lambda1) + 1\n","        # creating noise\n","        w1 = sigma * np.random.randn(n).reshape(-1, 1)\n","\n","        if dual_bs: # create second set of matrices\n","            A_1 = np.sqrt(1 / (2*n)) * np.random.randn(n, N)\n","            A_2 = A_1.copy()\n","            _, Lambda1, _ = np.linalg.svd(A_1)\n","            L1 = np.max(Lambda1) + 1\n","            L2 = L1\n","            w2 = sigma * np.random.randn(n).reshape(-1, 1)\n","\n","        if fading:  # real valued, 1 BS fading\n","            # creating fading effects -> N(0,1)\n","            h_uL1 = np.random.rayleigh(size=N)\n","            h_uL1 = np.diag(h_uL1)\n","            # sensing matrix with fading applied\n","            A_1 = A_1 @ h_uL1\n","            # finding thresholding parameter\n","            _, Lambda1, _ = np.linalg.svd(A_1)\n","            L1 = np.max(Lambda1) + 1\n","\n","            if noise: # real, 1 BS, noise, fading\n","                y_uL1 = A_1 @ x_uL + w1\n","            else:\n","                y_uL1 = A_1 @ x_uL\n","\n","            if dual_bs:\n","                # creating fading effects -> CN(0,1)\n","                h_uL2 = np.random.rayleigh(size=N)\n","                h_uL2 = np.diag(h_uL2)\n","                # sensing matrix with fading applied\n","                A_2 = A_2 @ h_uL2\n","                # finding thresholding parameter\n","                _, Lambda1, _ = np.linalg.svd(A_2)\n","                L2 = np.max(Lambda1) + 1\n","                if noise:\n","                    y_uL2 = A_2 @ x_uL + w1\n","                else:\n","                    y_uL2 = A_2 @ x_uL\n","\n","        else:  # no fading, real values\n","            if noise:\n","                y_uL1 = A_1 @ x_uL + w1\n","            else:\n","                y_uL1 = A_1 @ x_uL\n","\n","            if dual_bs:\n","                if noise:\n","                    y_uL2 = A_2 @ x_uL + w2\n","                else:\n","                    y_uL2 = A_2 @ x_uL\n","\n","    return A_1, A_2, x_uL, y_uL1, y_uL2, L1, L2"],"metadata":{"id":"nQfHvqGTztrl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ISTA Functions"],"metadata":{"id":"GtFDwF3b0xLg"}},{"cell_type":"code","source":["def ist_mse_iter(sys_param, tfs, num_iterations, avg):\n","'''sys_param holds n,N,k vals and sigma\n","  tfs (true-falses) holds system information\n","  avg: the number of trials to average over\n","  num_iterations: the number of iterations of the algorithm to run through\n","  returns the MSE per iterations\n","'''\n","\n","    alpha = .25  # predetermined for the 1 BS case\n","    # unwrap the arguments\n","    n,N,k,sigma = sys_param\n","    noise, fading, dual_bs, cmplx = tfs\n","\n","    # create the matrix to hold the results\n","    mse_per_iteration = np.zeros(num_iterations)\n","    \n","    for j in range(avg):  # average over a given number of trials\n","      A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)  # make the data needed\n","      \n","      if dual_bs: # concatenate the necessary vectors then proceed\n","          A1 = np.vstack((A1,A2))\n","          y_uL1 = np.vstack((y_uL1,y_uL2))\n","          _, Lambda2, _ = np.linalg.svd(A1)\n","          L1 = np.max(Lambda2) + 1\n","          alpha = alpha / 2 # half the single BS case\n","\n","      if cmplx:\n","          xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","          # create the weights for ISTA\n","          x_weight = np.eye(N) - (1/L1)*(A1.conj().T @ A1)\n","          y_weight = (1/L1)*A1.conj().T\n","              \n","      else:\n","          xHt = np.zeros(x_uL.shape)\n","          # creating weights\n","          x_weight = np.eye(N) - (1/L1)*(A1.T @ A1)\n","          y_weight = (1/L1)*A1.T\n","\n","      # this part is same for complex or real\n","      for idx in range(num_iterations): # iterate through ISTA\n","          update = (x_weight @ xHt) + (y_weight @ y_uL1)\n","          xHt = eta(update, alpha/L1, cmplx)\n","          \n","          # update the result after each iteration\n","          mse_per_iteration[idx] += (1/N) * np.sum(np.abs(x_uL - xHt)**2)\n","\n","        # return the average  \n","    return mse_per_iteration / avg"],"metadata":{"id":"Gua0AlSu02x3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ist_mse_snr(sys_param, tfs, num_iterations, avg):\n","'''sys_param holds n,N,k vals and sigma\n","  tfs (true-falses) holds system information\n","  avg: the number of trials to average over\n","  num_iterations: the number of iterations of the algorithm to run through\n","  returns the MSE for vs some SNRs'''\n","\n","\n","    alpha = .25  # predetermined for the 1 BS case\n","    # unwrap the arguments\n","    n,N,k,sigma = sys_param\n","    noise, fading, dual_bs, cmplx = tfs\n","\n","    if dual_bs: # halve the alpha value\n","      alpha = alpha/2\n","\n","    # creating noise matrix\n","    SNRdB = np.array([-12,-10, -5, 1, 5, 10, 20])  # in dB\n","\n","    # convert out of dB and calculate the variance\n","    if dual_bs:\n","      SNRs = (10**(SNRdB/10))*2*n\n","    else:\n","      SNRs = (10**(SNRdB/10))*n\n","    sigmas = 1/(np.sqrt(SNRs))\n","\n","    # create matrix to hold the results\n","    mse_per_iteration = np.zeros(len(sigmas))\n","\n","    cnt = 0\n","    for sig in sigmas:  # loop through all the variance values\n","        mse = 0\n","        for i in range(avg):  # average the results over a given number of trials\n","          sys_param = (n,N,k,sig) # update sys_param with new variance for given SNR\n","          A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)  # make the data needed\n","\n","          if dual_bs: # concatenate the necessary vectors then proceed\n","            A1 = np.vstack((A1,A2))\n","            y_uL1 = np.vstack((y_uL1,y_uL2))\n","\n","          if cmplx:\n","            # create the estimate of x and its weights\n","            xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","            x_weight = np.eye(N) - (1/L1)*(A1.conj().T @ A1)\n","            y_weight = (1/L1)*A1.conj().T\n","              \n","          else:\n","            # create the estimate of x and its weights\n","            xHt = np.zeros(x_uL.shape)\n","            x_weight = np.eye(N) - (1/L1)*(A1.T @ A1)\n","            y_weight = (1/L1)*A1.T\n","\n","\n","          # ISTA\n","          for idx_iter in range(num_iterations):  # cycle through a set number of iterations\n","            update = (x_weight @ xHt) + (y_weight @ y_uL1)\n","            xHt = eta(update, alpha/L1, cmplx)\n","          # calculate mse after a complete cycle of ISTA iterations\n","          mse_per_iteration[cnt] += (1/N) * np.sum(np.abs(x_uL - xHt)**2)\n","        cnt += 1 # update cnt after all the avg trials have finished and move on to the next variance\n","\n","            # average the result\n","    return mse_per_iteration / avg"],"metadata":{"id":"bS5lDEtX1nWG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ist_md_fa(sys_param, tfs, num_iterations, avg, threshold):\n","  '''sys_param holds n,N,k vals and sigma\n","  tfs (true-falses) holds system information\n","  avg: the number of trials to average over\n","  num_iterations: the number of iterations of the algorithm to run through\n","  threshold: the value above which a user is considered active\n","  returns the number of MD/FA vs iterations'''\n","\n","   # unwrap the input tuples\n","    n,N,k,sigma = sys_param\n","    noise, fading, dual_bs, cmplx = tfs\n","    \n","    # create the results matrices\n","    ista_fa = np.zeros(num_iterations)\n","    ista_md = np.zeros(num_iterations)\n","      \n","\n","    for j in range(avg):\n","      # create new data\n","      A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)\n","\n","      if dual_bs: # concatenate the necessary vectors then proceed\n","          A1 = np.vstack((A1,A2))\n","          y_uL1 = np.vstack((y_uL1,y_uL2))\n","\n","      # find active users\n","      real_users = np.where(x_uL == 1)[0]\n","\n","      # create initial estimate of x and weights\n","      if cmplx:\n","        x_weight = np.eye(N) - (1/L1)*(A1.conj().T @ A1)\n","        y_weight = (1/L1)*A1.conj().T\n","        xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","      else:\n","        x_weight = np.eye(N) - (1/L1)*(A1.T @ A1)\n","        y_weight = (1/L1)*A1.T\n","        xHt = np.zeros(x_uL.shape)\n","\n","      for idx in range(num_iterations):  # iterate through ISTA\n","          update = (x_weight @ xHt) + (y_weight @ y_uL1)\n","          xHt = eta(update, alpha/L1, cmplx)\n","\n","          # find detection errors at each iteration\n","          xHt_user_guess = np.where(abs(xHt) > threshold)[0]\n","          fa = np.setdiff1d(xHt_user_guess, real_users)  # returns the guessed values that aren't in real ones. aka False Alarm\n","          md = np.setdiff1d(real_users, xHt_user_guess)  # real values that aren't in the guessed ones. aka Misdetection\n","\n","          ista_fa[idx] += len(fa)\n","          ista_md[idx] += len(md)\n","\n","\n","    # divide it out by the number of averages\n","    ista_md = ista_md / avg\n","    ista_fa = ista_fa / avg\n","\n","    return ista_md, ista_fa  # return the results"],"metadata":{"id":"jWbwYER72wK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ist_md_fa_snr(sys_param, tfs, num_iterations, avg, threshold):\n","   '''sys_param holds n,N,k vals and sigma\n","  tfs (true-falses) holds system information\n","  avg: the number of trials to average over\n","  num_iterations: the number of iterations of the algorithm to run through\n","  threshold: the value above which a user is considered active\n","  returns the number of MD/FA vs SNR'''\n","\n","  # unwrap parameters\n","  n,N,k,sigma = sys_param\n","  noise, fading, dual_bs, cmplx = tfs\n","\n","   # creating noise matrix\n","  SNRdB = np.array([-12,-10, -5, 1, 5, 10, 20]) # in dB\n","\n","  # convert out of dB and find variance\n","  if dual_bs:\n","    SNRs = (10**(SNRdB/10))*2*n\n","  else:\n","    SNRs = (10**(SNRdB/10))*n\n","  sigmas = 1/(np.sqrt(SNRs))\n","\n","  # create result matrices\n","  ista_snr_fa = np.zeros(len(sigmas))\n","  ista_snr_md = np.zeros(len(sigmas))\n","\n","  cnt = 0 \n","  for sig in sigmas: # loop through all the variance values\n","    for j in range(avg):\n","      # create new data\n","      sys_param = (n,N,k,sig)\n","      A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)\n","      \n","      if dual_bs: # concatenate the necessary vectors then proceed\n","          A1 = np.vstack((A1,A2))\n","          y_uL1 = np.vstack((y_uL1,y_uL2))\n","\n","      # find the active users\n","      real_users = np.where(x_uL == 1)[0]\n","\n","      # create initial estimate of x and weights\n","      if cmplx:\n","        x_weight = np.eye(N) - (1/L1)*(A1.conj().T @ A1)\n","        y_weight = (1/L1)*A1.conj().T\n","        xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","      else:\n","        x_weight = np.eye(N) - (1/L1)*(A1.T @ A1)\n","        y_weight = (1/L1)*A1.T\n","        xHt = np.zeros(x_uL.shape)\n","\n","      # iterate through ISTA for the given number of iterations\n","      for idx in range(num_iterations):\n","          update = (x_weight @ xHt) + (y_weight @ y_uL1)\n","          xHt = eta(update, alpha/L1, cmplx)\n","\n","      # find detection errors\n","      xHt_user_guess = np.where(abs(xHt) > threshold)[0]\n","      fa = np.setdiff1d(xHt_user_guess, real_users)  # returns the guessed values that aren't in real ones. aka False Alarm\n","      md = np.setdiff1d(real_users, xHt_user_guess)  # real values that aren't in the guessed ones. aka Misdetection\n","      ista_snr_fa[cnt] += len(fa)\n","      ista_snr_md[cnt] += len(md)\n","\n","    cnt += 1\n","\n","  # divide it out by the number of averages\n","  ista_snr_md = ista_snr_md / avg\n","  ista_snr_fa = ista_snr_fa / avg\n","\n","  return ista_snr_md, ista_snr_fa"],"metadata":{"id":"TR67HmW_3PDN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AMP Functions"],"metadata":{"id":"_pM1KzSc37cI"}},{"cell_type":"code","source":["# used for real valued AMP\n","def onsager(z, r, tau):\n","# calculates and returns the onsager correction term\n","  n = len(z)\n","  return (z/n) * np.sum(eta(r, tau,cmplx) != 0)"],"metadata":{"id":"nFYO18PI4A2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# used for complex valued AMP\n","# defined in the equations section\n","def complex_soft_thresholding(x, T):\n","  eps = 1e-9\n","  return (np.abs(x) > T)*(np.abs(x) - T)*(x/np.abs(x+eps))\n","\n","def complex_soft_thresholding_derivative(xHt, T):\n","  eps = 1e-9\n","  xr = np.real(xHt).flatten()\n","  xi = np.imag(xHt).flatten()\n","  den = (xr**2 + xi**2)**(3/2) + eps\n","  indicator = ((xr**2 + xi**2) > T**2).astype(float)\n","  \n","  dRdr = indicator*(1-T*xi**2/den)\n","  dIdi = indicator*(1-T*xr**2/den)\n","\n","  return dRdr, dIdi"],"metadata":{"id":"OM0ip08P38lZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def amp_mse_iter(sys_param, tfs, num_iterations, avg): \n","'''sys_param holds n,N,k vals and sigma\n","  tfs (true-falses) holds system information\n","  avg: the number of trials to average over\n","  num_iterations: the number of iterations of the algorithm to run through\n","  returns the MSE per iterations'''\n","\n","    # unwrap the inputs\n","    n,N,k,sigma = sys_param\n","    noise, fading, dual_bs, cmplx = tfs\n","\n","    # create result vector\n","    mse_per_iteration = np.zeros(num_iterations)\n","\n","    for j in range(avg):  # average over a given number of trials\n","      A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)  # make the data needed\n","\n","      if dual_bs: # concatenate the necessary vectors then proceed\n","          A1 = np.vstack((A1,A2))\n","          y_uL1 = np.vstack((y_uL1,y_uL2))\n","      \n","      if cmplx: # run complex AMP\n","          xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","          z = y_uL1 - (A1@xHt)\n","\n","          for idxit in range(num_iterations):\n","            # update estimate of x\n","            r = A1.conj().T @ z + xHt\n","            sigma_hat = 1/np.sqrt(np.log(2))*np.median(np.abs(r))\n","            xHt = complex_soft_thresholding(r, sigma_hat)\n","            # calculate residual error\n","            etaderR, etaderI = complex_soft_thresholding_derivative(r, sigma_hat);\n","            z = y_uL1 - A1@xHt + z*(np.sum(etaderR)+np.sum(etaderI))/(2*n);\n","            mse_per_iteration[idxit] += np.linalg.norm(xHt.flatten() - x_uL.flatten())**2 / N\n","          \n","      \n","      else: # run real valued AMP\n","          z = np.zeros(y_uL1.shape)\n","          xHt = np.zeros(x_uL.shape)\n","          r = 0\n","          tau = 0\n","          ons = 0\n","\n","          for idx_iter in range(num_iterations):\n","              ons = onsager(z, r, tau)\n","              z = y_uL1 - A1 @ xHt + ons\n","              if dual_bs:  # tau is varied in two BS case by factor of 1/sqrt(2)\n","                tau = np.sqrt(1/(2*n)) * np.linalg.norm(z)\n","              else:\n","                tau = np.sqrt(1/n) * np.linalg.norm(z)              \n","              r = xHt + A1.T @ z\n","              xHt = eta(r, tau, cmplx)\n","\n","              # find the current error\n","              mse_per_iteration[idx_iter] += (1/N) * np.sum(abs(x_uL - xHt)**2)\n","    \n","    # average out the result\n","    return mse_per_iteration / avg"],"metadata":{"id":"3zHZmThj4Oa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def amp_mse_snr(sys_param, tfs, num_iterations, avg):\n","'''sys_param holds n,N,k vals and sigma\n","tfs (true-falses) holds system information\n","avg: the number of trials to average over\n","num_iterations: the number of iterations of the algorithm to run through\n","returns the MSE for some SNRs'''\n","\n","    alpha = .25  # predetermined for the 1 BS case\n","    # unwrap the inputs\n","    n,N,k,sigma = sys_param\n","    noise, fading, dual_bs, cmplx = tfs\n","\n","    # creating noise matrix\n","    SNRdB = np.array([-12,-10, -5, 1, 5, 10, 20]) # in dB\n","\n","    # get out of dB and calculate the variance\n","    if dual_bs:\n","      SNRs = (10**(SNRdB/10))*2*n\n","    else:\n","      SNRs = (10**(SNRdB/10))*n\n","    sigmas = 1/(np.sqrt(SNRs))\n","    \n","    # create the result matrix\n","    mse_snr = np.zeros(len(sigmas))\n","\n","    cnt = 0  # keeps track of where we are in ur results matrix\n","    for sig in sigmas:  # loop through all the variance values\n","      mse = 0  # reset the mse for each new variance value\n","      for i in range(avg):  # average over a given number of trials\n","        # update sys_param with new variance value\n","        sys_param = (n,N,k,sig)\n","        A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)  # make the data needed\n","\n","        if dual_bs: # concatenate the necessary vectors then proceed\n","          A1 = np.vstack((A1,A2))\n","          y_uL1 = np.vstack((y_uL1,y_uL2))\n","\n","        if cmplx: # run complex AMP\n","            xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","            z = y_uL1 - (A1@xHt)\n","\n","            for idxit in range(num_iterations):\n","              # update the estimate of x\n","              r = A1.conj().T @ z + xHt\n","              sigma_hat = 1/np.sqrt(np.log(2))*np.median(np.abs(r))\n","              xHt = complex_soft_thresholding(r, sigma_hat)\n","              # calculate the residual error\n","              etaderR, etaderI = complex_soft_thresholding_derivative(r, sigma_hat);\n","              z = y_uL1 - A1@xHt + z*(np.sum(etaderR)+np.sum(etaderI))/(2*n);\n","            # find the MSE\n","            mse_snr[cnt] += np.linalg.norm(xHt.flatten() - x_uL.flatten())**2 / N\n","            \n","        \n","        else: # run real valued AMP\n","            z = np.zeros(y_uL1.shape)\n","            xHt = np.zeros(x_uL.shape)\n","            r = 0\n","            tau = 0\n","            ons = 0\n","\n","            for idx_iter in range(num_iterations):\n","                ons = onsager(z, r, tau)\n","                z = y_uL1 - A1 @ xHt + ons\n","                if dual_bs:\n","                  tau = np.sqrt(1/(2*n)) * np.linalg.norm(z)\n","                else:\n","                  tau = np.sqrt(1/n) * np.linalg.norm(z) \n","                r = xHt + A1.T @ z\n","                xHt = eta(r, tau, cmplx)\n","            # find the current error\n","            mse_snr[cnt] += (1/N) * np.sum((x_uL - xHt)**2)\n","  \n","      cnt+=1 # increase the count as you move to the next variance value\n","    return mse_snr / avg"],"metadata":{"id":"PYF7mMaI5HXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def amp_md_fa_iter(sys_param, tfs, num_iterations, avg, threshold):\n","'''sys_param holds n,N,k vals and sigma\n","tfs (true-falses) holds system information\n","avg: the number of trials to average over\n","num_iterations: the number of iterations of the algorithm to run through\n","returns the MD/FA vs iterations'''\n","\n","    # unwrap the input tuples\n","    n,N,k,sigma = sys_param\n","    noise, fading, dual_bs, cmplx = tfs\n","    \n","    # create results matrices\n","    fa_iter = np.zeros(num_iterations)\n","    md_iter = np.zeros(num_iterations)\n","\n","    for j in range(avg):\n","      # create new data\n","      A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)\n","\n","      # find active users\n","      real_users = np.where(x_uL == 1)[0]\n","\n","      if dual_bs: # concatenate the necessary vectors then proceed\n","          A1 = np.vstack((A1,A2))\n","          y_uL1 = np.vstack((y_uL1,y_uL2))\n","      \n","      if cmplx: # run complex AMP\n","          xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","          z = y_uL1 - (A1@xHt)\n","\n","          for idxit in range(num_iterations):\n","            # update estimate of x\n","            r = A1.conj().T @ z + xHt\n","            sigma_hat = 1/np.sqrt(np.log(2))*np.median(np.abs(r))\n","            xHt = complex_soft_thresholding(r, sigma_hat)\n","            # find the residual error\n","            etaderR, etaderI = complex_soft_thresholding_derivative(r, sigma_hat);\n","            z = y_uL1 - A1@xHt + z*(np.sum(etaderR)+np.sum(etaderI))/(2*n);\n","\n","            # find detection errors at each iteration\n","            xHt_user_guess = np.where(abs(xHt) > threshold)[0]\n","            fa = np.setdiff1d(xHt_user_guess, real_users)  # returns the guessed values that aren't in real ones. aka False Alarm\n","            md = np.setdiff1d(real_users, xHt_user_guess)  # real values that aren't in the guessed ones. aka Misdetection\n","            # add results to the matrices\n","            fa_iter[idxit] += len(fa)\n","            md_iter[idxit] += len(md)\n","      \n","      else: # run real valued AMP\n","          z = np.zeros(y_uL1.shape)\n","          xHt = np.zeros(x_uL.shape)\n","          r = 0\n","          tau = 0\n","          ons = 0\n","\n","          for idx_iter in range(num_iterations):\n","            ons = onsager(z, r, tau)\n","            z = y_uL1 - A1 @ xHt + ons\n","            if dual_bs:\n","              tau = np.sqrt(1/(2*n)) * np.linalg.norm(z)\n","            else:\n","              tau = np.sqrt(1/n) * np.linalg.norm(z) \n","            r = xHt + A1.T @ z\n","            xHt = eta(r, tau, cmplx)\n","\n","            # find detection errors\n","            xHt_user_guess = np.where(abs(xHt) > threshold)[0]\n","            fa = np.setdiff1d(xHt_user_guess, real_users)  # returns the guessed values that aren't in real ones. aka False Alarm\n","            md = np.setdiff1d(real_users, xHt_user_guess)  # real values that aren't in the guessed ones. aka Misdetection\n","\n","            fa_iter[idx_iter] += len(fa)\n","            md_iter[idx_iter] += len(md)\n","            \n","    # average out the result\n","    return md_iter / avg, fa_iter / avg"],"metadata":{"id":"EMCwLh167Za1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def amp_md_fa_snr(sys_param, tfs, num_iterations, avg, threshold):\n","'''sys_param holds n,N,k vals and sigma\n","tfs (true-falses) holds system information\n","avg: the number of trials to average over\n","num_iterations: the number of iterations of the algorithm to run through\n","returns the MD/FA vs SNRs'''\n","\n","  # unwrap parameters\n","  n,N,k,sigma = sys_param\n","  noise, fading, dual_bs, cmplx = tfs\n","\n"," # creating noise matrix\n","  SNRdB = np.array([-12,-10, -5, 1, 5, 10, 20]) # in dB\n","  # convert out of dB and find the variance\n","  if dual_bs:\n","    SNRs = (10**(SNRdB/10))*2*n\n","  else:\n","    SNRs = (10**(SNRdB/10))*n\n","  sigmas = 1/(np.sqrt(SNRs))\n","\n","  # create the result vectors\n","  fa_snr = np.zeros(len(sigmas))\n","  md_snr = np.zeros(len(sigmas))\n","\n","  cnt = 0 \n","  for sig in sigmas:  # loop through all the variance values\n","    for j in range(avg):  # average over a given number of trials\n","      # create new data\n","      sys_param = (n,N,k,sig)  # update the sys_param with new variance value\n","      A1, A2, x_uL, y_uL1, y_uL2, L1, L2 = make_data(sys_param, tfs)\n","\n","      # find the active users\n","      real_users = np.where(x_uL == 1)[0]\n","\n","      if dual_bs: # concatenate the necessary vectors then proceed\n","          A1 = np.vstack((A1,A2))\n","          y_uL1 = np.vstack((y_uL1,y_uL2))\n","\n","      if cmplx: # run complex AMP\n","          xHt = np.zeros(x_uL.shape, dtype=np.complex_)\n","          z = y_uL1 - (A1@xHt)\n","\n","          for idxit in range(num_iterations):\n","            # update the estimate of x\n","            r = A1.conj().T @ z + xHt\n","            sigma_hat = 1/np.sqrt(np.log(2))*np.median(np.abs(r))\n","            xHt = complex_soft_thresholding(r, sigma_hat)\n","            # calculate the residual error\n","            etaderR, etaderI = complex_soft_thresholding_derivative(r, sigma_hat);\n","            z = y_uL1 - A1@xHt + z*(np.sum(etaderR)+np.sum(etaderI))/(2*n);\n","          # find detection errors\n","          xHt_user_guess = np.where(abs(xHt) > threshold)[0]\n","          fa = np.setdiff1d(xHt_user_guess, real_users)  # returns the guessed values that aren't in real ones. aka False Alarm\n","          md = np.setdiff1d(real_users, xHt_user_guess)  # real values that aren't in the guessed ones. aka Misdetection\n","\n","          # add the results to the matrices\n","          fa_snr[cnt] += len(fa)\n","          md_snr[cnt] += len(md)\n","      \n","      else: # run real valued AMP\n","          z = np.zeros(y_uL1.shape)\n","          xHt = np.zeros(x_uL.shape)\n","          r = 0\n","          tau = 0\n","          ons = 0\n","\n","          for idx_iter in range(num_iterations):\n","              ons = onsager(z, r, tau)\n","              z = y_uL1 - A1 @ xHt + ons\n","              if dual_bs:\n","                tau = np.sqrt(1/(2*n)) * np.linalg.norm(z)\n","              else:\n","                tau = np.sqrt(1/n) * np.linalg.norm(z) \n","              r = xHt + A1.T @ z\n","              xHt = eta(r, tau, cmplx)\n","\n","          # find detection errors\n","          xHt_user_guess = np.where(abs(xHt) > threshold)[0]\n","          fa = np.setdiff1d(xHt_user_guess, real_users)  # returns the guessed values that aren't in real ones. aka False Alarm\n","          md = np.setdiff1d(real_users, xHt_user_guess)  # real values that aren't in the guessed ones. aka Misdetection\n","          fa_snr[cnt] += len(fa)\n","          md_snr[cnt] += len(md)\n","    cnt+=1 \n","\n","    # return the averaged results\n","  return md_snr / avg, fa_snr / avg"],"metadata":{"id":"71ZHIZyL8FxX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LISTA Functions"],"metadata":{"id":"0SsvEc5Nztfg"}},{"cell_type":"code","source":["# thresholding function for complex LISTA\n","def tf_cmplx_eta(u,T):\n","  return tf.math.exp(tf.complex(0.0,tf.math.angle(u))) * tf.complex(tf.math.maximum(tf.math.abs(u)-T, 0),0.0)"],"metadata":{"id":"7_RaPzdXzvgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CRF_LISTALayer(keras.layers.Layer):\n","  # class used to create our network layers\n","  \n","  # defining variables for the layer\n","  def __init__(self, A, L, init_alpha, Q, W):\n","    # initialize the weights of the system\n","    super().__init__()\n","    self.A = A\n","    self.L = L\n","    self.n, self.N = self.A.shape\n","    # init values for the following weights are calculated later\n","    self.alpha = tf.Variable(initial_value=init_alpha, dtype='float32', trainable=True)\n","    self.Q = tf.Variable(initial_value=init_Q, dtype='complex64', trainable=True)\n","    self.W = tf.Variable(initial_value=init_W, dtype='complex64', trainable=True)\n","\n","  # creating inputs and updating things on each call\n","  def call(self, inputs):\n","    # separating the x and y\n","    xHt = inputs[:, 0:self.N]\n","    y = inputs[:, self.N:]\n","    update = xHt @ self.Q + y @ self.W  # weighting and combining the vectors\n","    new_x = tf_cmplx_eta(update, self.alpha/self.L)  # thresholding and updating x\n","    return tf.concat([new_x, y], axis=1)  # reconcatenate x and y\n","\n","class CustomMSELoss(keras.losses.Loss):\n","# custom loss function b/c we have x and y concatenated\n","  def __init__(self, N):\n","    super().__init__()\n","    self.N = N\n","  \n","  def call(self, true, pred):\n","    # separate x and y and then compute MSE\n","    x_true = true[:, 0:self.N]\n","    x_pred = pred[:, 0:self.N]\n","    return tf.reduce_mean(tf.math.squared_difference(tf.complex(x_true,0.0), x_pred))\n","  \n","class CustomMSEMetric(keras.metrics.Mean):\n","# custom metric function b/c we have x and y concatenated\n","  def __init__(self, N):\n","    super().__init__()\n","    self.N = N\n","\n","  def update_state(self, true, pred, sample_weight=None):\n","    # separate x and y and then compute the MSE\n","    x_true = true[:, 0:self.N]\n","    x_pred = pred[:, 0:self.N]\n","    val = tf.reduce_mean(tf.math.squared_difference(tf.complex(x_true,0.0), x_pred))\n","    return super().update_state(val, sample_weight=None)"],"metadata":{"id":"pow3PYADz33y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LISTA"],"metadata":{"id":"NpwtjOQCzkni"}},{"cell_type":"code","source":["# define problem parameters\n","n = 270\n","N = 1024\n","k = 400\n","\n","# for MD, FA\n","threshold = .4\n","num_layers = 15\n","\n","# define number of training/validation/testing samples\n","num_train_samples = 75000\n","num_valid_samples = 25000\n","num_test_samples = 25000\n","total_num_samples = num_train_samples + num_valid_samples + num_test_samples\n","\n","# use default rng\n","rng = np.random.default_rng()\n","\n","# change these values as you wish to create your system model\n","cmplx = True\n","dual_bs = False\n","fading = True\n","noise = True\n","snr_dB = 5 "],"metadata":{"id":"4lzI-ydCzl_S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Make the data set**"],"metadata":{"id":"vidaAsng00Bj"}},{"cell_type":"code","source":["# specify the original alpha value\n","init_alpha = 0.3\n","\n","# create sensing matrix\n","if cmplx:\n","  if dual_bs:\n","    # create sensing matrix A - will stack so energy of col of A = 1/2\n","    A = np.sqrt(1/(4*n))*np.random.randn(n, N) + 1j*np.sqrt(1/(4*n))*np.random.randn(n, N)  \n","  else:\n","    A = np.sqrt(1/(2*n))*np.random.randn(n, N) + 1j*np.sqrt(1/(2*n))*np.random.randn(n, N)\n","else:\n","  if dual_bs:\n","    A = np.sqrt(1 / (2*n)) * np.random.randn(n, N) \n","  else:\n","    A = np.sqrt(1 / n) * np.random.randn(n, N)\n","\n","# creates the appropiate sigma\n","if dual_bs:\n","  snr = (10**(snr_dB/10))*2*n  # correct SNR def for 2 BS\n","else:\n","  snr = (10**(snr_dB/10))*n \n","sigma = 1/(np.sqrt(snr))\n","\n","# create noise vector(s)\n","w1 = []\n","for i in range(total_num_samples):\n","  if cmplx:\n","    w1.append(np.sqrt((sigma**2)/2) * np.random.randn(n) + 1j*np.sqrt((sigma**2)/2) * np.random.randn(n))\n","  else:\n","    w1.append(sigma*np.random.randn(n))\n","w1 = np.array(w1)\n","\n","if dual_bs:\n","  w2 = []\n","  for i in range(total_num_samples):\n","    if cmplx:\n","      w2.append(np.sqrt((sigma**2)/2) * np.random.randn(n) + 1j*np.sqrt((sigma**2)/2) * np.random.randn(n))\n","    else:\n","      w2.append(sigma*np.random.randn(n))\n","  w2 = np.array(w2)\n","  w1 = np.hstack((w1,w2))  # stack to make one noise vector if it is dual BS\n","\n","# create fading effects\n","if fading:\n","  # creating fading effects\n","  h = np.sqrt(1/2)*np.random.randn(N) + 1j*np.sqrt(1/2)*np.random.randn(N) \n","  h = np.diag(h)  # creates a diagonal matrix of all the h coefficients\n","\n","  # matrix with fading added\n","  A1 = A @ h\n","\n","  if dual_bs: # create second set of fading coefficents\n","    h2 = np.sqrt(1/2)*np.random.randn(N) + 1j*np.sqrt(1/2)*np.random.randn(N) \n","    h2 = np.diag(h2) \n","\n","    A2 = A @ h2\n","    # now stack and make one A\n","    A = np.vstack((A1, A2))\n","\n","  else:\n","    A = A1  # assign it with the one BS fading case\n","\n","if dual_bs and not fading:\n","  # A is just stacked with itself if no fading\n","  A = np.vstack((A,A))\n","\n","# creating initial values for trainable parameters\n","_, Lambda, _ = np.linalg.svd(A)\n","L = np.max(Lambda) + 1\n","\n","init_Q = np.eye(N) - (A.T @ A) / L\n","init_W = A / L\n","\n","# create the x vectors\n","x = np.zeros((total_num_samples, N))\n","idx_nonzero = rng.permuted(np.tile(np.arange(N), (total_num_samples, 1)), axis=1)\n","for i in range(k): # k-sparse\n","  x[np.arange(total_num_samples), idx_nonzero[:, i].flatten()] = 1\n","\n","# create the received y vectors\n","if noise:\n","  y = x @ A.T + w  # adding noise here\n","else:\n","  y = x @ A.T\n","y = np.hstack((np.zeros((total_num_samples, N)), y))\n","\n","# Divide data into training, validation, testing sets\n","train_data = y[0:num_train_samples, :]\n","train_labels = x[0:num_train_samples, :]\n","valid_data = y[num_train_samples:num_train_samples+num_valid_samples, :]\n","valid_labels = x[num_train_samples:num_train_samples+num_valid_samples, :]\n","test_data = y[num_train_samples+num_valid_samples:, :]\n","test_labels = x[num_train_samples+num_valid_samples:, :]"],"metadata":{"id":"xsWpW0jb02oH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Create the network with 'num_layers' layers**"],"metadata":{"id":"ZBpb7Q7c3tR6"}},{"cell_type":"code","source":["# this allows you to find number of MD/FA for a 'num_layers' layer network\n","# you are also able to see the MSE after the given number of layers\n","\n","learn_rate = .0001  # custom learning rate\n","op = keras.optimizers.Adam(learning_rate=learn_rate)\n","\n","# creating the input\n","input = keras.layers.Input(shape=(n+N,), name='y_inputs',dtype='complex64')\n","for idx_layer in range(num_layers):  # creates a given number of layers\n","  # calls the layer differently depending on what layer it is \n","  if num_layers == 1:\n","    output = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (input)\n","  elif num_layers > 1:\n","    if idx_layer == 0:\n","      x_hidden = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (input)\n","    elif idx_layer == num_layers - 1:  # output is populated on the last layer\n","      output = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (x_hidden)\n","    else:\n","      x_hidden = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (x_hidden)\n","   \n","model = keras.Model(inputs=input, outputs=output, name='CRF_LISTAModel')\n","# compile keras model\n","custom_mse_loss = CustomMSELoss(N)\n","custom_mse_metric = CustomMSEMetric(N)\n","model.compile(optimizer=op, loss=custom_mse_loss, metrics=[custom_mse_metric])\n","\n","# train model\n","history = model.fit(train_data,\n","                  train_labels,\n","                  batch_size=128,\n","                  epochs=50,\n","                  validation_data=(valid_data, valid_labels))\n","\n","# evaluate the model\n","results = model.evaluate(test_data, test_labels)\n","print(results) # prints the MSE after a fixed number of layers"],"metadata":{"id":"uqjHklzc3sgG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To find MD/FA vs. SNR you can run the above cell with a different SNR then run the following cell and keep track of the SNRs you use as well as the results. These results can then be plotted.\n","\n","Similar process can be done to find MSE vs. SNR for a fixed number of layers"],"metadata":{"id":"CBQFI0MU5pnS"}},{"cell_type":"code","source":["# Find the number of MD/FA\n","xHt = model.predict(test_data)  # guesses based on our network\n","xHt = xHt.T[:N,:]\n","xHt = xHt.T  # maniulated xHt to be useable\n","x = test_labels   # actual values\n","\n","# create arrys to hold data\n","fa_ar = np.zeros(num_test_samples)\n","md_ar = np.zeros(num_test_samples)\n","\n","for i in range(num_test_samples):\n","  # user is active if value above a certain threshold\n","  user_guess = np.where(abs(xHt[i]) > threshold)\n","  real_users = np.where(abs(x[i]) == 1)\n","  # FA if the user is said as active, but not in real users\n","  fa_ar[i] = len(np.setdiff1d(user_guess, real_users))\n","  # MD if a user is in the real_users array, but was not guessed to be active\n","  md_ar[i] = len(np.setdiff1d(real_users, user_guess))\n","\n","# average the results\n","avg_fa = sum(fa_ar) / num_test_samples\n","avg_fa_ar.append(avg_fa)\n","avg_md = sum(md_ar) / num_test_samples\n","avg_md_ar.append(avg_md)\n","\n","print(f'MD: {avg_md_ar}')\n","print(f'FA: {avg_fa_ar}')"],"metadata":{"id":"Fjyt7of04BHx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**The following cell allows you to find MSE or MD/FA vs. Number of layers**"],"metadata":{"id":"_0y38L1M55Bf"}},{"cell_type":"code","source":["cnt = 1  # initial number of layers used\n","\n","# create the results lists\n","lista_mse_cmplx = []\n","avg_fa_ar = []\n","avg_md_ar = []\n","\n","# custom learning rate\n","learn_rate = .0001\n","op = keras.optimizers.Adam(learning_rate=learn_rate)\n","\n","for i in range(num_layers):\n","  # create initial input\n","  input = keras.layers.Input(shape=(n+N,), name='y_inputs',dtype='complex64')\n","  for idx_layer in range(cnt):\n","    # calls the layer differently depending on what layer it is \n","    if cnt == 1:\n","      output = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (input)\n","    elif cnt > 1:\n","      if idx_layer == 0:\n","        x_hidden = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (input)\n","      elif idx_layer == cnt - 1:  # output is populated on the last layer\n","        output = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (x_hidden)\n","      else:\n","        x_hidden = CRF_LISTALayer(A, L, init_alpha, init_Q, init_W) (x_hidden)\n","    \n"," # increase count so it goes through more iterations next time\n","  cnt += 1\n","\n","  model = keras.Model(inputs=input, outputs=output, name='CRF_LISTAModel')\n","  # compile keras model\n","  custom_mse_loss = CustomMSELoss(N)\n","  custom_mse_metric = CustomMSEMetric(N)\n","  model.compile(optimizer=op, loss=custom_mse_loss, metrics=[custom_mse_metric])\n","\n","  # train model\n","  history = model.fit(train_data,\n","                    train_labels,\n","                    batch_size=128,\n","                    epochs=50,\n","                    validation_data=(valid_data, valid_labels))\n","\n","  # evaluate the model and display the results\n","  results = model.evaluate(test_data, test_labels)\n","  lista_mse_cmplx.append(results[0])  # results represents MSE\n","\n","  ## find MD, FA ##\n","  xHt = model.predict(test_data)\n","  xHt = xHt.T[:N,:]\n","  xHt = xHt.T  # rearrange xHt to be useable\n","  x = test_labels # contains the actual values of x\n","\n","  # create necessary results arrays\n","  fa_ar = np.zeros(num_test_samples)\n","  md_ar = np.zeros(num_test_samples)\n","  for i in range(num_test_samples): \n","    # user is actvie if the value at their index is above a certain threshold\n","    user_guess = np.where(abs(xHt[i]) > threshold)\n","    real_users = np.where(abs(x[i]) == 1)\n","    # FA if user is guessed as acitvce but not in real_users\n","    fa_ar[i] = len(np.setdiff1d(user_guess, real_users))\n","    # MD if user is in real_users but not guessed as active\n","    md_ar[i] = len(np.setdiff1d(real_users, user_guess))\n","\n","  # average the results\n","  avg_fa = sum(fa_ar) / num_test_samples\n","  avg_fa_ar.append(avg_fa)\n","  avg_md = sum(md_ar) / num_test_samples\n","  avg_md_ar.append(avg_md)\n","\n","# display the MD/FA vs. iterations results\n","print(f'MD: {avg_md_ar}')\n","print(f'FA: {avg_fa_ar}')"],"metadata":{"id":"1P0SogTr5-H9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pre-run data"],"metadata":{"id":"2hDemT1q9Pxk"}},{"cell_type":"code","source":["### include any pre run data to make graphs you want to save time ###"],"metadata":{"id":"1TUr1qu-9Tvt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Results"],"metadata":{"id":"jrJ9QdaU9Un3"}},{"cell_type":"markdown","source":["**System Parameters**"],"metadata":{"id":"y3sWnNbX9doR"}},{"cell_type":"code","source":["# k: number of active users\n","# N: number of total users\n","# n: number of measurements\n","k = 40\n","N = 1024\n","n = 270\n","\n","num_iterations = 15\n","num_avg = 10\n","alpha = .25\n","threshold = .4 # used for MD, FA\n","\n","dual_bs = False  # one or two base stations\n","cmplx = True     # real or complexed valued data\n","fading = True    # fading or no fading\n","noise = True     # noise or no noise\n","\n","# calculate noise parameters\n","snr_dB = 5   # enter an SNR in dB\n","if dual_bs:\n","  SNR = (10**(snr_dB/10))*n*2\n","else:\n","  SNR = (10**(snr_dB/10))*n\n","sigma = 1/(np.sqrt(SNR)) # calculate the variance\n","\n","# create tuples needed for functions\n","sys_param = (n,N,k,sigma)\n","tfs = (noise,fading,dual_bs,cmplx)"],"metadata":{"id":"RU3fy0Dt9Yj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ISTA: MSE vs. Iterations\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading} | Noise: {noise}')\n","if noise:\n","  print(f'SNR: {snr_dB}')\n","  \n","ista_mse_iter = ist_mse_iter(sys_param, tfs, num_iterations, num_avg)\n","print(np.array2string(ista_mse_iter, separator=','))"],"metadata":{"id":"WOX_9OoT-dSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AMP: MSE vs. Iterations\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading} | Noise: {noise}')\n","if noise:\n","  print(f'SNR: {snr_dB}')\n","  \n","amp_mse_iter = amp_mse_iter(sys_param, tfs, num_iterations, num_avg)\n","print(np.array2string(amp_mse_iter, separator=','))"],"metadata":{"id":"oyVGBALZ-PKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ISTA: MSE vs. SNR\n","# array of SNRs in dB to be tested over\n","SNRdB = np.array([-12,-10, -5, 1, 5, 10, 20])\n","SNRs = (10**(SNRdB/10))*n\n","sigmas = 1/(np.sqrt(SNRs))\n","\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading}')\n","\n","ista_mse_snr_ar = ist_mse_snr(sys_param, tfs, num_iterations, num_avg)\n","print(np.array2string(ista_mse_snr_ar, separator=','))"],"metadata":{"id":"oWCpgsNJ-5dz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AMP: MSE vs. SNR\n","# array of SNRs in dB to be tested over\n","SNRdB = np.array([-12,-10, -5, 1, 5, 10, 20])\n","SNRs = (10**(SNRdB/10))*n\n","sigmas = 1/(np.sqrt(SNRs))\n","\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading}')\n","\n","amp_mse_snr_ar = amp_mse_snr(sys_param, tfs, num_iterations, num_avg)\n","print(np.array2string(amp_mse_snr_ar, separator=','))"],"metadata":{"id":"Psfjd06P_Q2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ISTA MD/FA vs. Iterations\n","SNRs = (10**(snr_dB/10))*n\n","sigmas = 1/(np.sqrt(SNRs))\n","sys_param = (n,N,k,sigmas)\n","tfs = (noise,fading,dual_bs,cmplx)\n","\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading} | Noise: {noise}')\n","if noise:\n","  print(f'SNR: {snr_dB}')\n","\n","ista_md_iter, ista_fa_iter = ist_md_fa(sys_param, tfs, num_iterations, num_avg, threshold)\n","print(f'MD: {np.array2string(ista_md_iter, separator=',')}')\n","print(f'FA: {np.array2string(ista_fa_iter, separator=',')}')"],"metadata":{"id":"dVaNRKqxKHZn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AMP MD/FA vs. Iterations\n","SNRs = (10**(snr_dB/10))*n\n","sigmas = 1/(np.sqrt(SNRs))\n","sys_param = (n,N,k,sigmas)\n","tfs = (noise,fading,dual_bs,cmplx)\n","\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading} | Noise: {noise}')\n","if noise:\n","  print(f'SNR: {snr_dB}')\n","\n","amp_md_iter, amp_fa_iter = amp_md_fa_iter(sys_param, tfs, num_iterations, num_avg, threshold)\n","print(f'MD: {np.array2string(amp_md_iter, separator=',')}')\n","print(f'FA: {np.array2string(amp_fa_iter, separator=',')}')"],"metadata":{"id":"q3TqB0HxyaZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ISTA MD/FA vs. SNR\n","tfs = (noise, fading, dual_bs, cmplx)\n","\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading}')\n","\n","ista_md_snr, ista_fa_snr = ist_md_fa_snr(sys_param, tfs, num_iterations, num_avg, threshold)\n","print(f'MD: {np.array2string(ista_md_snr, separator=',')}')\n","print(f'FA: {np.array2string(ista_fa_snr, separator=',')}')"],"metadata":{"id":"UPp1Wve0ypOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AMP MD/FA vs. SNR\n","tfs = (noise, fading, dual_bs, cmplx)\n","\n","print(f'Dual BS: {dual_bs} | Complex: {cmplx} | Fading: {fading}')\n","\n","amp_md_snr, amp_fa_snr = amp_md_fa_snr(sys_param, tfs, num_iterations, num_avg, threshold)\n","print(f'MD: {np.array2string(amp_md_snr, separator=',')}')\n","print(f'FA: {np.array2string(amp_fa_snr, separator=',')}')"],"metadata":{"id":"okmKtTXyzEkv"},"execution_count":null,"outputs":[]}]}